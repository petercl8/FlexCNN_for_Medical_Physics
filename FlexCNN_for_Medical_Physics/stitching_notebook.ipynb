{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8gBjOYeJpAJ"
      },
      "source": [
        "# Notes: changed\n",
        "\n",
        "This code can perform the following tasks:\n",
        "\n",
        "\n",
        "*   Tune a CNN to directly reconstruct PET images from Sinograms (find a set of hyperparameters)\n",
        "*   Train a network with a given set of hyperparameters\n",
        "*   Test the network and record MSE and SSIM values for each image tested\n",
        "*   Visualize the data and test results\n",
        "*   Plot training curves, metric histograms, example images\n",
        "\n",
        "The code is organized into sections. The important sections that it makes sense to edit (or call) are:\n",
        "\n",
        "\n",
        "> **User Parameters** - Edit important user parameters and decide what the code will do\n",
        "\n",
        "> **(!) Run Pipeline** - Run cell to tune, train, or test networks, or visualize dataset.\n",
        "\n",
        "> **Analysis** - The cells nested here each have their own changeable parameters.\n",
        "\n",
        "*Notes:*\n",
        "\n",
        "*1) Ray Tune in particular is constantly changing. Therefore, if you are running this code after the authors have ceased maintaining it and there are errors, these are likely due to RayTune classes, methods, or functions being changed. Try loading an older version of Ray Tune.\n",
        "\n",
        "*2) This code was originally written to tune/train/test not just sinogram to image supervisory networks (sinogram-->image), but also image to sinogram supervisory networks, GANs, CycleGANs, and Cycle + Supervisory networks. These latter capabilities have not been updated, but much of the code survives for this functionality. In the future, the code may be updated once again have these capabilities.*\n",
        "\n",
        "\n",
        "GPUs\n",
        "====\n",
        "From best to worst:\n",
        "\n",
        "V100 - 6.92/hr\n",
        "\n",
        "L4 - 2.15/hr\n",
        "\n",
        "T4 - 1.7/hr\n",
        "\n",
        "v6e-1 TPU - 4.21/hr\n",
        "\n",
        "v5e-1 TPU - 4.11/hr\n",
        "\n",
        "v2-8 TPU - 1.82/hr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsbxljN96QMU"
      },
      "source": [
        "# User Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUTAEh3CDd0A"
      },
      "source": [
        "## General"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3uYaItCTDmA1"
      },
      "outputs": [],
      "source": [
        "\n",
        "#####################\n",
        "### General Setup ###\n",
        "#####################\n",
        "## Basic Options ##\n",
        "run_mode='train'  # Options: 'tune' , 'train' , 'test' , 'visualize' , 'none' ('none' builds dictionaries like you are visualizing but does not visualize)\n",
        "network_type='ACT'    # 'ACT', 'ATTEN', 'CONCAT', 'FROZEN_COFLOW', 'FROZEN_COUNTERFLOW' (Unmaintained: 'GAN', 'CYCLEGAN', 'SIMULT')\n",
        "train_SI=True         # If working with GAN or SUP networks, set to True build Sinogram-->Image networks, or False for Image --> Sinogram.\n",
        "\n",
        "## See note below for info about these options ##\n",
        "gen_sino_size=288         # Options: 180, 288, 320. Resize input sinograms to this size. Sinograms are square, which was found to give the best results.\n",
        "gen_image_size=180        # Image size (Options: 90). Images are square.\n",
        "gen_sino_channels=3       # Number of sinogram channels for network currently being trained. (usually 1 or 3)\n",
        "gen_image_channels=1      # Number of image channels for network currently being trained (generally 1)\n",
        "\n",
        "SI_normalize=False    # For sino-->image mappings: normalize CNN outputs (images), iterative recons, and ground truths from dataset. You can then adjust the scale factor in the search dictionaries.\n",
        "IS_normalize=False    # For image-->sinogram mappings: normalize CNN outputs (sinograms), projections, and ground truth sinograms from dataset. You can then adjust scale factor in search dicts.\n",
        "\n",
        "## Scales ##\n",
        "act_recon1_scale = 3.350  # If doing quantitative recons (no normalization), this is the scale factor to multiply optional recon1 by\n",
        "act_recon2_scale = 1.998  # If doing quantitative recons (no normalization), this is the scale factor to multiply optional recon2 by\n",
        "act_sino_scale   = 0.342  # If not normalizing sinograms, multiply sinograms by this factor\n",
        "act_image_scale  = 1      # If not normalizing images, multiply by this factor.\n",
        "                          # Set to 60 if you want to scale up activity maps to roughly equal counts/voxel (for our dataset).\n",
        "\n",
        "## Attenuation Image Scale ##\n",
        "atten_image_scale = 308.335  # Scale factor to multiply attenuation images by (attenuation sinograms are created on-the-fly)\n",
        "atten_sino_scale = 39.187140258382726\n",
        "\n",
        "## Resources ##\n",
        "# Resources With Which to Initialize Ray Tune #\n",
        "num_CPUs=12 # T4:8 L4/V100: 12\n",
        "num_GPUs=1\n",
        "\n",
        "# Set Resources Allocated per Trial #\n",
        "CPUs_per_trial=2\n",
        "GPUs_per_trial=1\n",
        "\n",
        "device_opt='sense' # Options: 'sense', 'cuda', 'cpu'. Set to 'sense' to set to 'cpu' if available, else 'cpu'.\n",
        "\n",
        "## Github Repository for Functions & Classes ##\n",
        "github_username='petercl8'\n",
        "repo_name='FlexCNN_for_Medical_Physics'\n",
        "\n",
        "## Directories ##\n",
        "project_colab_dirPath = '/content/drive/MyDrive/Colab/Working/'     # Directory, relative to which all other directories are specified (if working on Colab)\n",
        "project_local_dirPath = r'C:\\Users\\Peter Lindstrom\\My Drive (lindstrom.peter@gmail.com)\\Colab\\Working'  # Directory, relative to which all other directories are specified (if working Locally)\n",
        "\n",
        "local_repo_dirPath =  r'C:\\FlexCNN_cloned'\n",
        "\n",
        "data_dirName = 'dataset-sets'      # Dataset directory, placed in project directory (above)\n",
        "plot_dirName=  'plots'             # Plots Directory, placed in project directory (above)\n",
        "checkpoint_dirName='checkpoints'   # If not using Ray Tune (not tuning), PyTorch saves and loads checkpoint file from here\n",
        "                                   # All checkpoint files (for training, testing, visualizing) save the states for a particular network.\n",
        "                                   # Therefore, the hyperparameters for the loaded CNN must match the data in the checkpoint file.\n",
        "num_examples=-1                    # Number of examples from dataset to load. Set to -1 to use all examples (this is the default)\n",
        "\n",
        "\n",
        "# NOTE: The concatenation network type introduces a fundamental problem: the sinogram input to the generator has channel numbers not corresponding to either the attenuation or the activity sinogram. My solution is to let the dataloader handle its own business (detect data structure sizes, since it has access to them) but let the user determine the number ofgenerator channels, since the generator does not see the data until after it has been instantiated. Also, the user only determines channels for currently trained network. Any frozen networks are always an attenuation network, so I hardcode channel information for dataloader and generator accordingly. Conclusion: sino_channels and image_channels represent the input and output channels for the generator for the currently trained network only.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDx4D3QNDjan"
      },
      "source": [
        "## Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WLF8KOT6DwC2"
      },
      "outputs": [],
      "source": [
        "############\n",
        "## Tuning ##\n",
        "############\n",
        "# Note: When tuning, ALWAYS select \"restart session and run all\" from Runtime menu in Google Colab, or there may be bugs.\n",
        "#tune_csv_file='frame-fullSet-highCountSino2actMap-tunedLDM-L' # .csv file to save tuning dataframe to\n",
        "tune_csv_file='temp'\n",
        "#tune_exp_name='search-fullSet-highCountSino2actMap-tunedLDM-L'  # Experiment directory: Ray tune (and Tensorboard) write to this directory, relative to tune_storage_dirName.\n",
        "tune_exp_name='temp'\n",
        "\n",
        "tune_scheduler = 'ASHA'      # Use FIFO for simple first in/first out to train to the end, or ASHA to early stop poorly performing trials.\n",
        "tune_dataframe_fraction=0.33 # The fraction of the max tuning steps (tune_max_t) at which to save values to the tuning dataframe.\n",
        "tune_restore=False           # Restore a run (from the file tune_exp_name in tune_storage_dirPath). Use this if a tuning run terminated early for some reason.\n",
        "tune_minutes = 240           # How long to run RayTune. 180 minutes is good for 180x180 input.\n",
        "tune_metric = 'CR_symmetric'   # Tune for which optimization metric? For val set: 'MSE', 'SSIM', 'CUSTOM' (user defined in the code). For QA set: 'CR_symmetric', 'hot_underestimation', 'cold_overestimation'\n",
        "tune_even_reporting=True     # Set to True to ensure we report to Raytune at an even number of training examples, regardless of batch size.\n",
        "tune_batches_per_report=4    # If tune_even_reporting = False, this is the number of batches per report (15 works pretty well).\n",
        "tune_examples_per_report=10  # 512*4 # If tune_even_reporting = True, this is the number of training examples per Raytune report (~4 batches*512 examples/batch is a good number)\n",
        "tune_grace_period=4          # Minimum number of reports before terminating a trial\n",
        "tune_max_t = 25              # Maximum number of reports per network. For even training example reporting (reports made at a constant number of training\n",
        "                             # examples), 25 is a good number for ASHA. For FIFO, 12 is a good number. For debugging, try 10.\n",
        "                             # For constant batch size reporting (tune_even_reporting=False), 35 works well.\n",
        "tune_report_for='val'        # Set to 'val' to report IQA metrics using or cross-validation set. Set to 'qa' to use contrast recovery coefficients for QA phantoms.\n",
        "tune_eval_batch_size=128     # If tuning on validation or QA set, what is the batch size? Performance on several of these batches are averaged per Ray Tune report (see NUM_EVAL_BATCHES in code)\n",
        "tune_augment=('SI', True)    # 'SI' (sinogram-->image or image--sinogram), \"II\" (image-->image) or None; True/False = augument by flipping along channels dimension?\n",
        "tune_debug=True             # Run logger to debug tuning\n",
        "tune_force_fixed_config=False# Force tuning with a fixed configuration dictionary. This is useful for debugging, to make sure that a network has a good architecture for learning.\n",
        "\n",
        "\n",
        "## Training Files ##\n",
        "## -------------- ##\n",
        "tune_act_sino_file = 'train-highCountSino-382x513.npy'\n",
        "#tune_act_sino_file= 'train-highCountSino-180x180.npy'\n",
        "#tune_act_sino_file='train-highCountImage.npy'\n",
        "#tune_act_sino_file='train-obliqueImage.npy'\n",
        "tune_act_image_file='train-actMap.npy'\n",
        "\n",
        "#tune_atten_image_file=None\n",
        "tune_atten_image_file='train-attenMap.npy'\n",
        "#tune_atten_sino_file=None\n",
        "tune_atten_sino_file='train-attenSino-382x513.npy'\n",
        "\n",
        "#tune_act_recon1_file=None\n",
        "#tune_act_recon2_file=None\n",
        "tune_act_recon1_file='train-highCountImage.npy' # Can set recon files to None if dataset does not have these.\n",
        "tune_act_recon2_file='train-obliqueImage.npy'\n",
        "\n",
        "## Cross Validation Set ##\n",
        "## -------------------- ##\n",
        "tune_val_act_sino_file='val-highCountSino-382x513.npy'\n",
        "#tune_val_act_sino_file='val-highCountSino-180x180.npy'\n",
        "#tune_val_act_sino_file='val-highCountImage.npy'\n",
        "#tune_val_act_sino_file='val-obliqueImage.npy'\n",
        "tune_val_act_image_file='val-actMap.npy'\n",
        "\n",
        "tune_val_atten_image_file=None\n",
        "tune_val_atten_sino_file=None\n",
        "\n",
        "# QA Phantoms #\n",
        "tune_qa_hot_weight=0.5 # A weighted contrast recovery coefficient is reported to ray tune as follows: ROI_NEMA_hot * tune_qa_hot_weight + ROI_NEMA_cold * (1-tune_qa_hot_weight)\n",
        "tune_qa_act_sino_file='QA-NEMA-highCountSino.npy'\n",
        "tune_qa_act_image_file='QA-NEMA-actMap.npy'\n",
        "tune_qa_hotMask_file='QA-NEMA-hotMask_17mm.npy'\n",
        "tune_qa_hotBackgroundMask_file='QA-NEMA-backMask_17mm.npy'\n",
        "tune_qa_coldMask_file='QA-NEMA-coldMask_37mm.npy'\n",
        "tune_qa_coldBackgroundMask_file='QA-NEMA-backMask_37mm.npy'\n",
        "\n",
        "tune_qa_atten_image_file=None\n",
        "tune_qa_atten_sino_file=None\n",
        "\n",
        "\n",
        "## Unlikely to Change ##\n",
        "tune_storage_dirName='searches'     # Create tuning folders (one for each experiment, each of which contains multiple trials) in this directory. Leave blank ('') to place search files in project directory\n",
        "tune_dataframe_dirName= 'dataframes-tune'  # Directory for tuning dataframe (stores network information for each network trialed). Code will create it if it doesn't exist."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7C3ZYnMDoa5"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "D3zRfuhUDzm-"
      },
      "outputs": [],
      "source": [
        "##############\n",
        "## Training ##\n",
        "##############\n",
        "#train_checkpoint_file='checkpoint-fullSet-highCountSino2actMap-tunedLDM-augSI-100epochs' # Checkpoint file to load or save to.\n",
        "                           # For dual network training, checkpoints are autmatically appended suffixes of -atten and -act.\n",
        "train_checkpoint_file='temp'\n",
        "\n",
        "train_load_state=False     # Set to True to load pretrained weights. Use if training terminated early.\n",
        "train_save_state=False     # Save network weights to train_checkpoint_file file as it trains\n",
        "train_epochs = 200         # Number of training epochs.\n",
        "train_display_step=20      # Number of steps/visualization. Good values: for supervised learning or GAN, set to: 50, For cycle-consistent, set to 20\n",
        "train_sample_division=1    # To evenly sample the training set by a given factor, set this to an integer greater than 1 (ex: to sample every other example, set to 2)\n",
        "train_show_times=False     # Show calculation times during training?\n",
        "\n",
        "\n",
        "## Data Files & Augmentations ##\n",
        "## -------------------------- ##\n",
        "train_shuffle=True\n",
        "train_augment=('SI', True)     # 'SI' (sinogram-->image or image--sinogram), \"II\" (image-->image) or None; True/False = augument by flipping along channels dimension?\n",
        "#train_augment=('II', True)\n",
        "train_act_sino_file= 'val-highCountSino-382x513.npy'\n",
        "#train_act_sino_file='train-highCountImage.npy'\n",
        "\n",
        "train_act_image_file='val-actMap.npy'\n",
        "#train_act_image_file='train-anniMap.npy'\n",
        "\n",
        "#rain_atten_image_file=None\n",
        "train_atten_image_file='val-attenMap.npy'\n",
        "train_atten_sino_file='val-attenSino-382x513.npy'\n",
        "\n",
        "train_act_recon1_file=None\n",
        "train_act_recon2_file=None\n",
        "#train_act_recon1_file='train-highCountImage.npy'  # Can set recon files to None if dataset does not have these.\n",
        "#train_act_recon2_file='train-obliqueImage.npy'\n",
        "#train_act_recon1_file='train-actMap.npy'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZGwlOGCDpj-"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hesQrZyVD1Xd"
      },
      "outputs": [],
      "source": [
        "###########\n",
        "# Testing #\n",
        "###########\n",
        "test_dataframe_dirName= 'TestOnFull'  # Directory for test metric dataframes\n",
        "test_csv_file = 'combined-tunedLowSSIM-trainedLowSSIM-onTestSet-wMLEM' # csv dataframe file to save testing results to\n",
        "test_checkpoint_file='checkpoint-tunedLowSSIM-trainedLowSSIM-100epochs' # Checkpoint to load model for testing\n",
        "\n",
        "test_display_step=15        # Make this a larger number to save bit of time (displays images/metrics less often)\n",
        "test_batch_size=25          # This doesn't affect the final metrics, just the displayed metrics as testing procedes\n",
        "test_chunk_size=875              # How many examples do you want to test at once? NOTE: This should be a multiple of test_batch_size AND also go into the test set size evenly.\n",
        "testset_size=35000          # Size of the set to test. This must be <= the number of examples in your test set file.\n",
        "test_begin_at=0             # Begin testing at this example number.\n",
        "test_compute_MLEM=False          # Compute a simple MLEM reconstruction from the sinograms when running testing.\n",
        "                            # This takes a lot longer. If set to false, only FBP is calculated.\n",
        "test_merge_dataframes=True  # Merge the smaller/chunked dataframes at the end of the test run into one large dataframe?\n",
        "test_show_times=False       # Show calculation times?\n",
        "test_shuffle=False\n",
        "test_sample_division=1\n",
        "\n",
        "## Select Data Files ##\n",
        "## ----------------- ##\n",
        "test_act_sino_file= 'test-highCountSino-180x180.npy'\n",
        "test_act_image_file= 'test-actMap.npy'\n",
        "\n",
        "test_atten_image_file=None\n",
        "test_atten_sino_file=None\n",
        "\n",
        "test_act_recon1_file='test-highCountImage.npy'\n",
        "test_act_recon2_file='test-obliqueImage.npy'\n",
        "\n",
        "#test_act_sino_file=  'test_sino-35k.npy'\n",
        "#test_act_image_file= 'test_image-35k.npy'\n",
        "#test_act_sino_file= 'test_sino-highMSE-8750.npy'\n",
        "#test_act_image_file= 'test_image-highMSE-8750.npy'\n",
        "#test_act_sino_file= 'test_sino-lowMSE-8750.npy'\n",
        "#test_act_image_file= 'test_image-lowMSE-8750.npy'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AVXtlTSDqhl"
      },
      "source": [
        "## Visualizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "D67HJlNMD3m-"
      },
      "outputs": [],
      "source": [
        "####################\n",
        "## Visualize Data ##\n",
        "####################\n",
        "#visualize_act_sino_file= 'train-highCountSino-180x180.npy'\n",
        "visualize_act_sino_file= 'train-highCountSino-382x513.npy'\n",
        "visualize_act_image_file='train-actMap.npy'\n",
        "visualize_act_recon1_file='train-highCountImage.npy'  # Can set recon files to None if dataset does not have these.\n",
        "visualize_act_recon2_file='train-obliqueImage.npy'\n",
        "#visualize_act_recon1_file=None\n",
        "#visualize_act_recon2_file=None\n",
        "\n",
        "visualize_atten_image_file=None\n",
        "visualize_atten_sino_file=None\n",
        "\n",
        "#visualize_checkpoint_file='checkpoint-90x1-tunedMSE-fc6-6epochs' # Checkpoint file to load/save\n",
        "visualize_checkpoint_file='checkpoint-new_data-old_net-180x180-temp'\n",
        "visualize_batch_size = 10   # Set value to exactly 120 to see a large grid of images OR =<10 for reconstructions\n",
        "                            #  and ground truth with matched color scales\n",
        "visualize_offset=0          # Image to begin at. Set to 0 to start at beginning.\n",
        "visualize_shuffle=True      # Shuffle data set when visualizing?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdfEsglDIfJ3"
      },
      "source": [
        "# Install Required Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtQhjpz9RUD7"
      },
      "source": [
        "## Some Setup Funcs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TOlPJH8MGx21"
      },
      "outputs": [],
      "source": [
        "import os, sys, glob, importlib, inspect, types, subprocess, pkgutil\n",
        "\n",
        "def sense_colab():\n",
        "    try:\n",
        "        import google.colab\n",
        "        IN_COLAB = True\n",
        "    except ImportError:\n",
        "        IN_COLAB = False\n",
        "    return IN_COLAB\n",
        "\n",
        "def sense_device(device='sense'):\n",
        "    if device == 'sense':\n",
        "        if torch.cuda.is_available():\n",
        "            device = 'cuda'\n",
        "        else:\n",
        "            device = 'cpu'\n",
        "    elif device == 'cpu':\n",
        "        device = 'cpu'\n",
        "    elif device == 'cuda':\n",
        "        device = 'cuda'\n",
        "    return device\n",
        "\n",
        "def install_required_packages(IN_COLAB=True, force_reinstall=False, include_optional=True):\n",
        "    \"\"\"\n",
        "    Installs required Python packages efficiently.\n",
        "    - Detects if running in Colab or locally.\n",
        "    - Installs missing packages only (unless force_reinstall=True).\n",
        "    - Ensures Ray Tune dependencies are installed even if ray is already present.\n",
        "    \"\"\"\n",
        "\n",
        "    # Base list of packages\n",
        "    packages = [\n",
        "        \"torch\", \"torchvision\", \"torchaudio\",\n",
        "        \"ray[tune]\", \"tensorboardX\", \"hyperopt\",\n",
        "        \"numpy\", \"pandas\", \"matplotlib\",\n",
        "        \"scikit-image\", \"scipy\"\n",
        "    ]\n",
        "\n",
        "    # Optional packages for visualization\n",
        "    optional_packages = [\"tensorboard\"]\n",
        "    # Widgets for tqdm are optional; plain progress bar is fine\n",
        "    widgets_packages = [\"ipywidgets\"]\n",
        "    missing = []\n",
        "\n",
        "    for pkg in packages:\n",
        "        pkg_name = pkg.split(\"[\")[0]\n",
        "\n",
        "        # Special handling for Ray Tune\n",
        "        if pkg_name == \"ray\":\n",
        "            try:\n",
        "                import ray\n",
        "                import ray.tune\n",
        "                ray_tune_installed = True\n",
        "            except ImportError:\n",
        "                ray_tune_installed = False\n",
        "            if force_reinstall or not ray_tune_installed:\n",
        "                missing.append(pkg)\n",
        "            continue\n",
        "\n",
        "        # General case\n",
        "        if importlib.util.find_spec(pkg_name) is None or force_reinstall:\n",
        "            missing.append(pkg)\n",
        "\n",
        "    # Optionally add optional packages\n",
        "    if include_optional:\n",
        "        missing += optional_packages + widgets_packages\n",
        "\n",
        "    if not missing:\n",
        "        print(\"âœ… All required packages already installed.\")\n",
        "        return\n",
        "\n",
        "    print(f\"ðŸ“¦ Installing missing packages: {', '.join(missing)}\")\n",
        "\n",
        "    # Build pip command\n",
        "    if IN_COLAB:\n",
        "        cmd = [\"pip\", \"install\", \"--upgrade\"] + missing\n",
        "    else:\n",
        "        cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\"] + missing\n",
        "\n",
        "    try:\n",
        "        subprocess.check_call(cmd)\n",
        "        print(\"âœ… Installation complete.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"âŒ Installation failed: {e}\")\n",
        "\n",
        "def install_required_packages_ray_version(IN_COLAB, force_reinstall=False, include_optional=True, ray_version=None):\n",
        "    \"\"\"\n",
        "    Installs required Python packages efficiently.\n",
        "    - Detects if running in Colab or locally.\n",
        "    - Installs missing packages only (unless force_reinstall=True).\n",
        "    - Ensures Ray Tune dependencies are installed even if ray is already present.\n",
        "    - Can pin Ray version with ray_version (e.g., \"1.12.0\").\n",
        "    \"\"\"\n",
        "\n",
        "    # Base list of packages\n",
        "    packages = [\n",
        "        \"torch\", \"torchvision\", \"torchaudio\",\n",
        "        \"ray[tune]\", \"tensorboardX\", \"hyperopt\",\n",
        "        \"numpy\", \"pandas\", \"matplotlib\",\n",
        "        \"scikit-image\", \"scipy\"\n",
        "    ]\n",
        "\n",
        "    # Optional packages for visualization\n",
        "    optional_packages = [\"tensorboard\"]\n",
        "    widgets_packages = [\"ipywidgets\"]\n",
        "    missing = []\n",
        "\n",
        "    for pkg in packages:\n",
        "        pkg_name = pkg.split(\"[\")[0]\n",
        "\n",
        "        # Special handling for Ray Tune\n",
        "        if pkg_name == \"ray\":\n",
        "            try:\n",
        "                import ray\n",
        "                import ray.tune\n",
        "                ray_tune_installed = True\n",
        "            except ImportError:\n",
        "                ray_tune_installed = False\n",
        "\n",
        "            # Build the package name with version if specified\n",
        "            if ray_version:\n",
        "                pkg = f\"ray[{ 'tune' if 'tune' in pkg else ''}]=={ray_version}\"\n",
        "\n",
        "            if force_reinstall or not ray_tune_installed:\n",
        "                missing.append(pkg)\n",
        "            continue\n",
        "\n",
        "        # General case\n",
        "        if importlib.util.find_spec(pkg_name) is None or force_reinstall:\n",
        "            missing.append(pkg)\n",
        "\n",
        "    # Optionally add optional packages\n",
        "    if include_optional:\n",
        "        missing += optional_packages + widgets_packages\n",
        "\n",
        "    if not missing:\n",
        "        print(\"âœ… All required packages already installed.\")\n",
        "        return\n",
        "\n",
        "    print(f\"ðŸ“¦ Installing missing packages: {', '.join(missing)}\")\n",
        "\n",
        "    # Build pip command\n",
        "    if IN_COLAB:\n",
        "        cmd = [\"pip\", \"install\", \"--upgrade\"] + missing\n",
        "    else:\n",
        "        cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\"] + missing\n",
        "\n",
        "    try:\n",
        "        subprocess.check_call(cmd)\n",
        "        print(\"âœ… Installation complete.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"âŒ Installation failed: {e}\")\n",
        "\n",
        "def install_required_packages_forceGPU(IN_COLAB=True, force_reinstall=False, include_optional=True):\n",
        "    \"\"\"\n",
        "    Installs required Python packages efficiently.\n",
        "    - Detects if running in Colab or locally.\n",
        "    - Installs missing packages only (unless force_reinstall=True).\n",
        "    - Automatically installs GPU-enabled PyTorch if a CUDA-capable GPU is detected.\n",
        "    \"\"\"\n",
        "\n",
        "    # Base list of non-PyTorch packages\n",
        "    other_packages = [\n",
        "        \"ray[tune]\", \"tensorboardX\", \"hyperopt\",\n",
        "        \"numpy\", \"pandas\", \"matplotlib\",\n",
        "        \"scikit-image\", \"scipy\"\n",
        "    ]\n",
        "\n",
        "    # Optional packages\n",
        "    optional_packages = [\"tensorboard\"]\n",
        "    widgets_packages = [\"ipywidgets\"]\n",
        "\n",
        "    missing = []\n",
        "\n",
        "    # ------------------------------\n",
        "    # PyTorch: detect CPU vs GPU\n",
        "    # ------------------------------\n",
        "    torch_packages = [\"torch\", \"torchvision\", \"torchaudio\"]\n",
        "    pip_index_url = []\n",
        "\n",
        "    cuda_available = False\n",
        "    try:\n",
        "        import torch\n",
        "        cuda_available = torch.cuda.is_available()\n",
        "    except ImportError:\n",
        "        pass\n",
        "\n",
        "    if not IN_COLAB and not cuda_available:\n",
        "        # Check GPU presence on Windows via nvidia-smi\n",
        "        try:\n",
        "            gpu_info = subprocess.check_output(\"nvidia-smi\", shell=True).decode()\n",
        "            if \"failed\" not in gpu_info.lower():\n",
        "                cuda_available = True\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # If local GPU detected, uninstall CPU-only PyTorch first and set CUDA URL\n",
        "    if cuda_available and not IN_COLAB:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"torch\", \"torchvision\", \"torchaudio\"])\n",
        "        except subprocess.CalledProcessError:\n",
        "            # Ignore if PyTorch is not installed\n",
        "            pass\n",
        "        pip_index_url = [\"--index-url\", \"https://download.pytorch.org/whl/cu124\"]\n",
        "\n",
        "    # ------------------------------\n",
        "    # Check other packages\n",
        "    # ------------------------------\n",
        "    for pkg in other_packages:\n",
        "        pkg_name = pkg.split(\"[\")[0]\n",
        "        if pkg_name == \"ray\":\n",
        "            try:\n",
        "                import ray\n",
        "                import ray.tune\n",
        "                ray_tune_installed = True\n",
        "            except ImportError:\n",
        "                ray_tune_installed = False\n",
        "            if force_reinstall or not ray_tune_installed:\n",
        "                missing.append(pkg)\n",
        "            continue\n",
        "\n",
        "        if importlib.util.find_spec(pkg_name) is None or force_reinstall:\n",
        "            missing.append(pkg)\n",
        "\n",
        "    # Add optional packages\n",
        "    if include_optional:\n",
        "        missing += optional_packages + widgets_packages\n",
        "\n",
        "    # Remove duplicates\n",
        "    missing = list(dict.fromkeys(missing))\n",
        "\n",
        "    if not missing and not force_reinstall:\n",
        "        print(\"âœ… All required packages already installed.\")\n",
        "        return\n",
        "\n",
        "    print(f\"ðŸ“¦ Installing missing packages: {', '.join(torch_packages + missing)}\")\n",
        "\n",
        "    # ------------------------------\n",
        "    # Build pip command\n",
        "    # ------------------------------\n",
        "    if IN_COLAB:\n",
        "        cmd = [\"pip\", \"install\", \"--upgrade\"] + torch_packages + missing + pip_index_url\n",
        "    else:\n",
        "        cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\"] + torch_packages + missing + pip_index_url\n",
        "\n",
        "    # ------------------------------\n",
        "    # Run pip install\n",
        "    # ------------------------------\n",
        "    try:\n",
        "        subprocess.check_call(cmd)\n",
        "        print(\"âœ… Installation complete.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"âŒ Installation failed: {e}\")\n",
        "\n",
        "    # ------------------------------\n",
        "    # Confirm CUDA availability\n",
        "    # ------------------------------\n",
        "    try:\n",
        "        import torch\n",
        "        if torch.cuda.is_available():\n",
        "            print(f\"âœ… PyTorch CUDA detected: {torch.cuda.get_device_name(0)}\")\n",
        "        else:\n",
        "            print(\"âš ï¸ PyTorch installed, but no GPU detected. Using CPU-only build.\")\n",
        "    except ImportError:\n",
        "        print(\"âŒ PyTorch installation failed completely.\")\n",
        "\n",
        "def refresh_repo(\n",
        "    IN_COLAB = True,\n",
        "    repo_name: str = \"FlexCNN_for_Medical_Physics\",\n",
        "    github_username: str = \"petercl8\",\n",
        "    local_repo_path: str = None,\n",
        "    auto_import: bool = True,\n",
        "    verbose: bool = True):\n",
        "    \"\"\"\n",
        "    Clone/pull and install the repo, then optionally auto-import all modules.\n",
        "    Also reloads all submodules to reflect changes without restarting the runtime.\n",
        "    \"\"\"\n",
        "    # --- Determine base directory ---\n",
        "    base_dir = \"/content\" if IN_COLAB else local_repo_path\n",
        "    if base_dir is None:\n",
        "        raise ValueError(\"local_repo_path must be provided if not in Colab\")\n",
        "\n",
        "    repo_path = os.path.join(base_dir, repo_name)\n",
        "    repo_url = (\n",
        "        f\"https://github.com/{github_username}/{repo_name}.git\"\n",
        "        if IN_COLAB\n",
        "        else f\"git@github.com:{github_username}/{repo_name}.git\"\n",
        "    )\n",
        "\n",
        "    # --- Clone or update ---\n",
        "    if not os.path.exists(repo_path):\n",
        "        if verbose:\n",
        "            print(f\"ðŸ“¦ Cloning {repo_name} into {base_dir}...\")\n",
        "        subprocess.run([\"git\", \"clone\", repo_url], cwd=base_dir, check=True)\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(f\"ðŸ”„ Pulling latest changes in {repo_path}...\")\n",
        "        subprocess.run([\"git\", \"pull\"], cwd=repo_path, check=True)\n",
        "\n",
        "    # --- Install package in editable mode ---\n",
        "    if verbose:\n",
        "        print(\"âš™ï¸ Installing the package in editable mode...\")\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \".\"],\n",
        "                   cwd=repo_path, check=True)\n",
        "\n",
        "    # --- Ensure repo path is importable ---\n",
        "    if repo_path not in sys.path:\n",
        "        sys.path.insert(0, repo_path)\n",
        "\n",
        "    # --- Import the package ---\n",
        "    package = importlib.import_module(repo_name)\n",
        "\n",
        "    # --- Reload all submodules recursively ---\n",
        "    def reload_submodules(pkg):\n",
        "        for _, modname, ispkg in pkgutil.walk_packages(pkg.__path__, pkg.__name__ + \".\"):\n",
        "            if modname in sys.modules:\n",
        "                importlib.reload(sys.modules[modname])\n",
        "            else:\n",
        "                importlib.import_module(modname)\n",
        "        importlib.reload(pkg)\n",
        "\n",
        "    reload_submodules(package)\n",
        "\n",
        "    # --- Gather all symbols ---\n",
        "    imported = {}\n",
        "    for _, modname, ispkg in pkgutil.walk_packages(package.__path__, package.__name__ + \".\"):\n",
        "        mod = importlib.import_module(modname)\n",
        "        for name, obj in inspect.getmembers(mod):\n",
        "            if not name.startswith(\"_\"):\n",
        "                imported[name] = obj\n",
        "\n",
        "    # --- Inject symbols into caller's globals if requested ---\n",
        "    if auto_import:\n",
        "        if verbose:\n",
        "            print(\"âœ¨ Injecting all symbols into global namespace...\")\n",
        "        caller_globals = inspect.stack()[1].frame.f_globals\n",
        "        caller_globals.update(imported)\n",
        "        if verbose:\n",
        "            print(f\"âœ… Setup complete: {len(imported)} symbols loaded into globals.\")\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(f\"âœ… Imported {len(imported)} symbols (not injected).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvYiUHTUk4ke"
      },
      "source": [
        "## Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpYLqzIhkzYt",
        "outputId": "d919c91e-2581-4f22-d18d-f4a81117f8d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¦ Installing missing packages: ray[tune], tensorboardX, scikit-image, tensorboard, ipywidgets\n",
            "âœ… Installation complete.\n"
          ]
        }
      ],
      "source": [
        "# --- Sense environment ---\n",
        "IN_COLAB = sense_colab()\n",
        "\n",
        "# --- Install packages and import ---\n",
        "install_required_packages(IN_COLAB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lb40jFSC0HEe"
      },
      "source": [
        "## Finish Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVzkxW7J6xlO",
        "outputId": "eba4e939-18bc-4419-cede-95e9da885741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”„ Pulling latest changes in /content/FlexCNN_for_Medical_Physics...\n",
            "âš™ï¸ Installing the package in editable mode...\n",
            "âœ¨ Injecting all symbols into global namespace...\n",
            "âœ… Setup complete: 212 symbols loaded into globals.\n",
            "CPUs available: 12\n",
            "GPUs available: 1\n",
            "  GPU 0: NVIDIA L4\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "=============\n",
            "Current Paths\n",
            "=============\n",
            "{'plot_dirPath': '/content/drive/MyDrive/Colab/Working/plots', 'checkpoint_dirPath': '/content/drive/MyDrive/Colab/Working/checkpoints', 'tune_storage_dirPath': '/content/drive/MyDrive/Colab/Working/searches', 'tune_dataframe_dirPath': '/content/drive/MyDrive/Colab/Working/dataframes-tune', 'test_dataframe_dirPath': '/content/drive/MyDrive/Colab/Working/TestOnFull', 'data_dirPath': '/content/drive/MyDrive/Colab/Working/dataset-sets', 'tune_act_sino_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/train-highCountSino-382x513.npy', 'tune_act_image_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/train-actMap.npy', 'tune_act_recon1_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/train-highCountImage.npy', 'tune_act_recon2_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/train-obliqueImage.npy', 'tune_atten_image_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/train-attenMap.npy', 'tune_atten_sino_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/train-attenSino-382x513.npy', 'tune_val_act_sino_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/val-highCountSino-382x513.npy', 'tune_val_act_image_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/val-actMap.npy', 'tune_val_atten_image_path': None, 'tune_val_atten_sino_path': None, 'tune_qa_act_sino_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/QA-NEMA-highCountSino.npy', 'tune_qa_act_image_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/QA-NEMA-actMap.npy', 'tune_qa_backMask_path': None, 'tune_qa_hotMask_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/QA-NEMA-hotMask_17mm.npy', 'tune_qa_hotBackgroundMask_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/QA-NEMA-backMask_17mm.npy', 'tune_qa_coldMask_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/QA-NEMA-coldMask_37mm.npy', 'tune_qa_coldBackgroundMask_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/QA-NEMA-backMask_37mm.npy', 'tune_qa_atten_image_path': None, 'tune_qa_atten_sino_path': None, 'train_act_sino_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/train-highCountSino-382x513.npy', 'train_act_image_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/train-actMap.npy', 'train_act_recon1_path': None, 'train_act_recon2_path': None, 'train_atten_image_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/train-attenMap.npy', 'train_atten_sino_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/train-attenSino-382x513.npy', 'test_act_sino_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/test-highCountSino-180x180.npy', 'test_act_image_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/test-actMap.npy', 'test_act_recon1_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/test-highCountImage.npy', 'test_act_recon2_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/test-obliqueImage.npy', 'test_atten_image_path': None, 'test_atten_sino_path': None, 'visualize_act_sino_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/train-highCountSino-382x513.npy', 'visualize_act_image_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/train-actMap.npy', 'visualize_act_recon1_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/train-highCountImage.npy', 'visualize_act_recon2_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/train-obliqueImage.npy', 'visualize_atten_image_path': None, 'visualize_atten_sino_path': None, 'act_sino_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/train-highCountSino-382x513.npy', 'act_image_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/train-actMap.npy', 'act_recon1_path': None, 'act_recon2_path': None, 'atten_image_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/train-attenMap.npy', 'atten_sino_path': '/content/drive/MyDrive/Colab/Working/dataset-sets/train-attenSino-382x513.npy', 'checkpoint_path': '/content/drive/MyDrive/Colab/Working/checkpoints/temp', 'tune_dataframe_path': '/content/drive/MyDrive/Colab/Working/dataframes-tune/temp.csv', 'test_dataframe_path': '/content/drive/MyDrive/Colab/Working/TestOnFull/combined-tunedLowSSIM-trainedLowSSIM-onTestSet-wMLEM.csv'}\n",
            "=============\n",
            "Current Settings\n",
            "=============\n",
            "{'run_mode': 'train', 'device': 'cuda', 'num_examples': -1, 'act_sino_scale': 0.342, 'act_recon1_scale': 3.35, 'act_recon2_scale': 1.998, 'act_image_scale': 1, 'atten_image_scale': 308.335, 'atten_sino_scale': 39.187140258382726, 'augment': ('SI', True), 'shuffle': True, 'num_epochs': 200, 'load_state': False, 'save_state': False, 'offset': 0, 'show_times': False, 'sample_division': 1, 'train_display_step': 20}\n",
            "=============\n",
            "Current Config\n",
            "=============\n",
            "{'SI_dropout': False, 'SI_exp_kernel': 4, 'SI_fixedScale': 1, 'SI_gen_fill': 0, 'SI_gen_final_activ': Sigmoid(), 'SI_gen_hidden_dim': 19, 'SI_gen_mult': 2.065329728174869, 'SI_gen_neck': 'medium', 'SI_gen_z_dim': 1181, 'SI_layer_norm': 'instance', 'SI_learnedScale_init': 4.2047521440377285, 'SI_normalize': False, 'SI_pad_mode': 'zeros', 'SI_skip_mode': 'add', 'batch_base2_exponent': 5, 'gen_b1': 0.22046050861804858, 'gen_b2': 0.152643657443423, 'gen_lr': 0.00099063275528607, 'gen_image_channels': 1, 'gen_image_size': 180, 'network_type': 'ACT', 'gen_sino_channels': 3, 'gen_sino_size': 288, 'sup_base_criterion': MSELoss(), 'SI_stats_criterion': PatchwiseMomentLoss(), 'SI_alpha_min': -1, 'SI_half_life_examples': 2000, 'SI_output_scale_lr_mult': 1.0, 'train_SI': True}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- Refresh Repository ---\n",
        "refresh_repo(IN_COLAB, local_repo_path=local_repo_dirPath)\n",
        "\n",
        "# --- Test Resources ---\n",
        "list_compute_resources()\n",
        "\n",
        "# --- Set main project directory\n",
        "project_dirPath = setup_project_dirs(IN_COLAB, project_local_dirPath, project_colab_dirPath, mount_colab_drive=True)\n",
        "\n",
        "# --- Set Device ---\n",
        "device = sense_device(device=device_opt)\n",
        "\n",
        "# Build grouped parameter dictionaries #\n",
        "\n",
        "common_settings = {\n",
        "    'run_mode': run_mode,\n",
        "    'device': device,\n",
        "    'num_examples': num_examples,\n",
        "    'act_recon1_scale': act_recon1_scale,\n",
        "    'act_recon2_scale': act_recon2_scale,\n",
        "    'act_sino_scale': act_sino_scale,\n",
        "    'act_image_scale': act_image_scale,\n",
        "    'atten_image_scale': atten_image_scale,\n",
        "    'atten_sino_scale': atten_sino_scale,\n",
        "}\n",
        "\n",
        "base_dirs = {\n",
        "    'project_dirPath': project_dirPath,\n",
        "    'plot_dirName': plot_dirName,\n",
        "    'checkpoint_dirName': checkpoint_dirName,\n",
        "    'tune_storage_dirName': tune_storage_dirName,\n",
        "    'tune_dataframe_dirName': tune_dataframe_dirName,\n",
        "    'test_dataframe_dirName': test_dataframe_dirName,\n",
        "    'data_dirName': data_dirName\n",
        "}\n",
        "\n",
        "data_files = {\n",
        "    'tune_act_sino_file': tune_act_sino_file,\n",
        "    'tune_act_image_file': tune_act_image_file,\n",
        "    'tune_act_recon1_file': tune_act_recon1_file,\n",
        "    'tune_act_recon2_file': tune_act_recon2_file,\n",
        "    'tune_atten_image_file': tune_atten_image_file,\n",
        "    'tune_atten_sino_file': tune_atten_sino_file,\n",
        "    'tune_val_act_sino_file': tune_val_act_sino_file,\n",
        "    'tune_val_act_image_file': tune_val_act_image_file,\n",
        "    'tune_val_atten_image_file': tune_val_atten_image_file,\n",
        "    'tune_val_atten_sino_file': tune_val_atten_sino_file,\n",
        "    'tune_qa_act_sino_file': tune_qa_act_sino_file,\n",
        "    'tune_qa_act_image_file': tune_qa_act_image_file,\n",
        "    'tune_qa_hotMask_file': tune_qa_hotMask_file,\n",
        "    'tune_qa_hotBackgroundMask_file': tune_qa_hotBackgroundMask_file,\n",
        "    'tune_qa_coldMask_file': tune_qa_coldMask_file,\n",
        "    'tune_qa_coldBackgroundMask_file': tune_qa_coldBackgroundMask_file,\n",
        "    'tune_qa_backMask_file': None, # Added this line to fix the KeyError\n",
        "    'tune_qa_atten_image_file': tune_qa_atten_image_file,\n",
        "    'tune_qa_atten_sino_file': tune_qa_atten_sino_file,\n",
        "    'train_act_sino_file': train_act_sino_file,\n",
        "    'train_act_image_file': train_act_image_file,\n",
        "    'train_act_recon1_file': train_act_recon1_file,\n",
        "    'train_act_recon2_file': train_act_recon2_file,\n",
        "    'train_atten_image_file': train_atten_image_file,\n",
        "    'train_atten_sino_file': train_atten_sino_file,\n",
        "    'test_act_sino_file': test_act_sino_file,\n",
        "    'test_act_image_file': test_act_image_file,\n",
        "    'test_act_recon1_file': test_act_recon1_file,\n",
        "    'test_act_recon2_file': test_act_recon2_file,\n",
        "    'test_atten_image_file': test_atten_image_file,\n",
        "    'test_atten_sino_file': test_atten_sino_file,\n",
        "    'visualize_act_sino_file': visualize_act_sino_file,\n",
        "    'visualize_act_image_file': visualize_act_image_file,\n",
        "    'visualize_act_recon1_file': visualize_act_recon1_file,\n",
        "    'visualize_act_recon2_file': visualize_act_recon2_file,\n",
        "    'visualize_atten_image_file': visualize_atten_image_file,\n",
        "    'visualize_atten_sino_file': visualize_atten_sino_file,\n",
        "    }\n",
        "\n",
        "mode_files = {\n",
        "    'tune_csv_file': tune_csv_file,\n",
        "    'train_checkpoint_file': train_checkpoint_file,\n",
        "    'test_checkpoint_file': test_checkpoint_file,\n",
        "    'test_csv_file': test_csv_file,\n",
        "    'visualize_checkpoint_file': visualize_checkpoint_file\n",
        "}\n",
        "\n",
        "network_opts = {\n",
        "    'network_type': network_type,\n",
        "    'train_SI': train_SI,\n",
        "    'gen_image_size': gen_image_size,\n",
        "    'gen_sino_size': gen_sino_size,\n",
        "    'gen_image_channels': gen_image_channels,\n",
        "    'gen_sino_channels': gen_sino_channels,\n",
        "    'SI_normalize': SI_normalize,\n",
        "    'IS_normalize': IS_normalize,\n",
        "}\n",
        "\n",
        "tune_opts = {\n",
        "    'tune_exp_name': tune_exp_name,\n",
        "    'tune_scheduler': tune_scheduler,\n",
        "    'tune_dataframe_fraction': tune_dataframe_fraction,\n",
        "    'tune_restore': tune_restore,\n",
        "    'tune_max_t': tune_max_t,\n",
        "    'tune_minutes': tune_minutes,\n",
        "    'tune_metric': tune_metric,\n",
        "    'tune_even_reporting': tune_even_reporting,\n",
        "    'tune_batches_per_report': tune_batches_per_report,\n",
        "    'tune_examples_per_report': tune_examples_per_report,\n",
        "    'tune_augment': tune_augment,\n",
        "    'tune_grace_period': tune_grace_period,\n",
        "    'tune_debug': tune_debug,\n",
        "    'tune_force_fixed_config': tune_force_fixed_config,\n",
        "    'tune_report_for': tune_report_for,\n",
        "    'tune_qa_hot_weight': tune_qa_hot_weight,\n",
        "    'tune_eval_batch_size': tune_eval_batch_size,\n",
        "    'num_CPUs': num_CPUs,\n",
        "    'num_GPUs': num_GPUs,\n",
        "    'cpus_per_trial': CPUs_per_trial,  # per trial\n",
        "    'gpus_per_trial': GPUs_per_trial,  # per trial\n",
        "}\n",
        "\n",
        "train_opts = {\n",
        "    'train_load_state': train_load_state,\n",
        "    'train_save_state': train_save_state,\n",
        "    'training_epochs': train_epochs,\n",
        "    'train_augment': train_augment,\n",
        "    'train_shuffle': train_shuffle,\n",
        "    'train_display_step': train_display_step,\n",
        "    'train_sample_division': train_sample_division,\n",
        "    'train_show_times': train_show_times,\n",
        "}\n",
        "\n",
        "test_opts = {\n",
        "    'test_display_step': test_display_step,\n",
        "    'test_batch_size': test_batch_size,\n",
        "    'test_chunk_size': test_chunk_size,\n",
        "    'testset_size': testset_size,\n",
        "    'test_begin_at': test_begin_at,\n",
        "    'test_compute_MLEM': test_compute_MLEM,\n",
        "    'test_merge_dataframes': test_merge_dataframes,\n",
        "    'test_show_times': test_show_times,\n",
        "    'test_shuffle': test_sample_division,\n",
        "    'test_sample_division': test_sample_division\n",
        "}\n",
        "\n",
        "viz_opts = {\n",
        "    'visualize_batch_size': visualize_batch_size,\n",
        "    'visualize_offset': visualize_offset,\n",
        "    'visualize_shuffle': visualize_shuffle,\n",
        "}\n",
        "\n",
        "# Build paths and settings using new functions\n",
        "paths = setup_paths(\n",
        "    run_mode=run_mode,\n",
        "    base_dirs=base_dirs,\n",
        "    data_files=data_files,\n",
        "    mode_files=mode_files,\n",
        "    test_ops=test_opts,\n",
        "    viz_ops=viz_opts\n",
        ")\n",
        "\n",
        "settings = setup_settings(\n",
        "    run_mode=run_mode,\n",
        "    common_settings=common_settings,\n",
        "    tune_opts=tune_opts,\n",
        "    train_opts=train_opts,\n",
        "    test_opts=test_opts,\n",
        "    viz_opts=viz_opts,\n",
        ")\n",
        "\n",
        "# --- Build Config Dictionary ---\n",
        "config = construct_config(\n",
        "    run_mode=run_mode,\n",
        "    network_opts=network_opts,\n",
        "    tune_opts=tune_opts,\n",
        "    test_opts=test_opts,\n",
        "    viz_opts=viz_opts,\n",
        "    config_ACT_SI=config_ACT_SI,\n",
        "    config_ACT_IS=config_ACT_IS,\n",
        "    config_ATTEN_SI=config_ATTEN_SI,\n",
        "    config_ATTEN_IS=config_ATTEN_IS,\n",
        "    config_CONCAT=config_CONCAT,\n",
        "    config_FROZEN_COFLOW=config_FROZEN_COFLOW,\n",
        "    config_FROZEN_COUNTERFLOW=config_FROZEN_COUNTERFLOW,\n",
        "    config_GAN_SI=None,\n",
        "    config_GAN_IS=None,\n",
        "    config_RAY_SI=config_RAY_SI,\n",
        "    config_RAY_SI_learnScale=config_RAY_SI_learnScale,\n",
        "    config_RAY_SI_fixedScale=config_RAY_SI_fixedScale,\n",
        "    config_RAY_IS=config_RAY_IS,\n",
        "    config_RAY_IS_learnScale=config_RAY_IS_learnScale,\n",
        "    config_RAY_IS_fixedScale=config_RAY_IS_fixedScale,\n",
        "    config_RAY_SUP=config_RAY_SUP,\n",
        "    config_RAY_SUP_FROZEN=config_RAY_SUP_FROZEN,\n",
        "    config_RAY_GAN=None,\n",
        "    config_RAY_GAN_CYCLE=None,\n",
        ")\n",
        "\n",
        "print (\"=============\")\n",
        "print (\"Current Paths\")\n",
        "print(\"=============\")\n",
        "print(paths)\n",
        "\n",
        "print (\"=============\")\n",
        "print (\"Current Settings\")\n",
        "print(\"=============\")\n",
        "print(settings)\n",
        "\n",
        "print (\"=============\")\n",
        "print(\"Current Config\")\n",
        "print(\"=============\")\n",
        "print(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aohugQ_mdq0"
      },
      "source": [
        "# (!) Run Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Tj_r32pumXbC",
        "outputId": "29528e84-d388-43f0-eebb-6a5e11e7bfb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/FlexCNN_for_Medical_Physics/FlexCNN_for_Medical_Physics/classes/dataset_classes.py:76: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:206.)\n",
            "  act_image_multChannel = torch.from_numpy(np.ascontiguousarray(act_image_array[index,:])).float() if act_image_array is not None else None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Dataset will be resized to image size: (1, 180, 180), sinogram size: (3, 288, 288). Note: channels are auto-detected from data when present.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (72) must match the size of tensor b (36) at non-singleton dimension 3",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1834951996.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# --- Run Pipeline ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m run_pipeline(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpaths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FlexCNN_for_Medical_Physics/FlexCNN_for_Medical_Physics/functions/main_run_functions/run_pipeline.py\u001b[0m in \u001b[0;36mrun_pipeline\u001b[0;34m(config, paths, settings, tune_opts, base_dirs, test_opts)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mrun_trainable_frozen_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mrun_trainable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mrun_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FlexCNN_for_Medical_Physics/FlexCNN_for_Medical_Physics/functions/main_run_functions/trainable.py\u001b[0m in \u001b[0;36mrun_trainable\u001b[0;34m(config, paths, settings)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0mgen_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                 \u001b[0mCNN_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrun_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCNN_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FlexCNN_for_Medical_Physics/FlexCNN_for_Medical_Physics/classes/generators.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, frozen_encoder_features, frozen_decoder_features, return_features)\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0mdecoder_feat_36\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskips\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_blocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 72 -> 144\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FlexCNN_for_Medical_Physics/FlexCNN_for_Medical_Physics/classes/generators.py\u001b[0m in \u001b[0;36m_merge\u001b[0;34m(self, skip, x)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'add'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'concat'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (72) must match the size of tensor b (36) at non-singleton dimension 3"
          ]
        }
      ],
      "source": [
        "# --- Refresh Repository ---\n",
        "#refresh_repo(IN_COLAB, local_repo_path=local_repo_dirPath)\n",
        "\n",
        "# --- Run Pipeline ---\n",
        "run_pipeline(\n",
        "    config=config,\n",
        "    paths=paths,\n",
        "    settings=settings,\n",
        "    tune_opts=tune_opts,\n",
        "    base_dirs=base_dirs,\n",
        "    test_opts=test_opts\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tunHHb885PKf"
      },
      "source": [
        "# Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9nGISvNMw09"
      },
      "source": [
        "## Compute Recon Scales\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKRUXmeeMWYw"
      },
      "outputs": [],
      "source": [
        "\n",
        "avg_activity = compute_average_activity_per_image(paths, dataset='train')\n",
        "#scales1 = compute_quantitative_reconstruction_scale(paths, dataset='train', compute_sinogram_scale=False)\n",
        "#scales2 = analyze_reconstruction_scale_distribution(paths, dataset='train', sample_mode='full', sample_size=1000, ratio_cap_multiple=None)\n",
        "#sinogram_scale = compute_sinogram_to_image_scale(paths, dataset='train', sample_number=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rUBhT1lARKm"
      },
      "source": [
        "**Absolute Activities (Training Set)**\n",
        "\n",
        "Annihilation: Average counts per image: 8676873\n",
        "\n",
        "Activity\n",
        "\n",
        "*   Average activity per image: 144616.84\n",
        "*   Std dev activity per image: 89057.51\n",
        "*   Min activity per image: 13.16\n",
        "*   Max activity per image: 640712.82\n",
        "\n",
        "Recon1: Average activity per image: 43167.45\n",
        "\n",
        "Recon2: Average activity per image: 72402.20\n",
        "\n",
        "Attenuation: 469.025\n",
        "\n",
        "**Activity Sinogram Scale**\n",
        "\n",
        "*   sample_sinogram_number=100, clip_percentile_low=10, clip_percentile_high=90, 'median': 0.341\n",
        "\n",
        "\n",
        "**Quantitative Reconstruction Scales:**\n",
        "\n",
        "Training Set:\n",
        "\n",
        "*   FORE: 3.350\n",
        "*   Oblique: 1.997\n",
        "*   Atten: 308.335\n",
        "\n",
        "Test Set:\n",
        "\n",
        "*   FORE: 3.412\n",
        "*   Oblique: 2.014\n",
        "\n",
        "**Analysis Scales for No Cap:**\n",
        "\n",
        "Training set:\n",
        "\n",
        "*   FORE: 3.400 +/- 0.305 (max_ratio = 4.768)\n",
        "*   Oblique: 2.025 +/- 0.077 (max_ratio = 2.658)\n",
        "\n",
        "Test set:\n",
        "\n",
        "*   FORE: 3.426 +/- 0.292 (max_ratio = 4.727)\n",
        "*   Oblique: 2.034 +/- 0.073 (max_ratio = 2.683)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngD0fv5BD-q8"
      },
      "source": [
        "## Adjust Atten Sino Alignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_BU2u7MD-q8"
      },
      "outputs": [],
      "source": [
        "# --- Refresh Repository ---\n",
        "refresh_repo(IN_COLAB, local_repo_path=local_repo_dirPath)\n",
        "\n",
        "visualize_sinogram_alignment(\n",
        "    paths,\n",
        "    settings,\n",
        "    num_examples=3,\n",
        "    scale_num_examples=100,\n",
        "    start_index=500,\n",
        "    randomize=True,\n",
        "    random_seed=None,\n",
        "    fig_size=3,\n",
        "    cmap='inferno',\n",
        "    circle=False,\n",
        "    theta_type='symmetrical', # Set to 'speed' to match activity sinogram angular sampling after pooling\n",
        "                        # Set to 'symmetrical' to match sampling before pooling.\n",
        "    # Activity resize/pad options\n",
        "    act_resize_type='crop_pad',   # 'crop_pad', 'bilinear', or None\n",
        "    act_pad_type='zeros', # 'sinoram' or 'zeros'\n",
        "    act_vert_size=288,\n",
        "    act_target_width=288,\n",
        "    act_pool_size=2,\n",
        "    # Attenuation resize/pad options\n",
        "    atten_resize_type='crop_pad', # 'crop_pad', 'bilinear', or None\n",
        "    atten_pad_type='zeros',\n",
        "    atten_vert_size=288,\n",
        "    atten_target_width=288,\n",
        "    atten_pool_size=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5qkU0fpHsKa"
      },
      "source": [
        "## Plot Example Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9PCpxBnHo07"
      },
      "outputs": [],
      "source": [
        "# --- Refresh Repository ---\n",
        "#refresh_repo(IN_COLAB, local_repo_path=local_repo_dirPath)\n",
        "\n",
        "## Anthropomorphic phantoms ##\n",
        "##############################\n",
        "fig_size_XCAT=2.5\n",
        "indexes_XCAT = [100, 200, 300, 400, 500, 600, 700]\n",
        "\n",
        "test_array_names = ['test-actMap.npy', 'test-obliqueImage.npy', 'test-highCountImage.npy',]\n",
        "test_sino = 'test-highCountSino-180x180.npy'\n",
        "#test_sino = 'test-highCountImage.npy'\n",
        "\n",
        "train_array_names = ['train-actMap.npy','train-obliqueImage.npy', 'train-highCountImage.npy', ]\n",
        "train_sino = 'train-highCountSino-180x180.npy'\n",
        "#train_sino = 'train-highCountImage.npy'\n",
        "\n",
        "## QA phantoms ##\n",
        "#################\n",
        "fig_size_QA=2.5\n",
        "indexes_QA = [13, 14, 15, 16, 17, 18, 19]\n",
        "\n",
        "NEMA_array_names = ['QA-NEMA-actMap.npy','QA-NEMA-obliqueImage.npy', 'QA-NEMA-highCountImage.npy',]\n",
        "NEMA_sino = 'QA-NEMA-highCountSino.npy'\n",
        "#NEMA_sino = 'QA-NEMA-highCountImage.npy'\n",
        "\n",
        "Pinwheel_array_names = ['QA-Pinwheel-actMap.npy','QA-Pinwheel-obliqueImage.npy', 'QA-Pinwheel-highCountImage.npy']\n",
        "Pinwheel_sino = 'QA-Pinwheel-highCountSino.npy'\n",
        "#Pinwheel_sino = 'QA-Pinwheel-highCountImage.npy'\n",
        "\n",
        "Radial_array_names = ['QA-Radial-actMap.npy','QA-Radial-obliqueImage.npy', 'QA-Radial-highCountImage.npy']\n",
        "Radial_sino = 'QA-Radial-highCountSino.npy'\n",
        "#Radial_sino = 'QA-Radial-highCountImage.npy'\n",
        "\n",
        "#actMap = 'QA-Axial-actMap.npy'\n",
        "#sino = 'QA-Axial-highCountSino.npy'\n",
        "\n",
        "## Network Configs ##\n",
        "#####################\n",
        "\n",
        "checkpoint_fileName_SI = 'checkpoint-fullSet-highCountSino2actMap-tunedSSIM-augII-100epochs'\n",
        "config_SI = {\n",
        "   \"SI_dropout\": False,\n",
        "  \"SI_exp_kernel\": 3,\n",
        "  \"SI_fixedScale\": 1,\n",
        "  \"SI_gen_fill\": 1,\n",
        "  \"SI_gen_final_activ\": nn.ELU(alpha=1.0),\n",
        "  \"SI_gen_hidden_dim\": 29,\n",
        "  \"SI_gen_mult\": 1.5090047574838394,\n",
        "  \"SI_gen_neck\": 11,\n",
        "  \"SI_gen_z_dim\": 486,\n",
        "  \"SI_layer_norm\": \"instance\",\n",
        "  \"SI_learnedScale_init\": 20.45467480669682,\n",
        "  \"SI_normalize\": False,\n",
        "  \"SI_pad_mode\": \"zeros\",\n",
        "  \"SI_skip_mode\": \"none\",\n",
        "  \"batch_base2_exponent\": 6,\n",
        "  \"gen_b1\": 0.34632557248900636,\n",
        "  \"gen_b2\": 0.10963336318792913,\n",
        "  \"gen_lr\": 0.0005750756280291565,\n",
        "  \"gen_image_channels\": 1,\n",
        "  \"gen_image_size\": 180,\n",
        "  \"network_type\": \"SUP\",\n",
        "  \"gen_sino_channels\": 3,\n",
        "  \"sino_size\": 180,\n",
        "  \"sup_criterion\": nn.MSELoss(),\n",
        "  \"train_SI\": True\n",
        "}\n",
        "\n",
        "####################\n",
        "### Plots Images ###\n",
        "####################\n",
        "\n",
        "#image_tensor, sino_tensor = PlotPhantomRecons(test_array_names, test_sino, config_SI, paths, indexes_XCAT, checkpoint_fileName_SI, fig_size_XCAT, device, settings)\n",
        "#show_single_unmatched_tensor(sino_tensor[0:2], fig_size=10)\n",
        "\n",
        "#image_tensor, sino_tensor = PlotPhantomRecons(NEMA_array_names, NEMA_sino, config_SI, paths, indexes_QA, checkpoint_fileName_SI, fig_size_QA, device, settings)\n",
        "image_tensor, sino_tensor = PlotPhantomRecons(Pinwheel_array_names, Pinwheel_sino, config_SI, paths, indexes_QA, checkpoint_fileName_SI, fig_size_QA, device, settings)\n",
        "show_single_unmatched_tensor(sino_tensor[0:2], fig_size=25)\n",
        "\n",
        "#image_tensor, sino_tensor = PlotPhantomRecons(Radial_array_names, Radial_sino, config_SI, paths, indexes_QA, checkpoint_fileName_SI, fig_size_QA, device, settings)\n",
        "\n",
        "#############\n",
        "## Metrics ##\n",
        "#############\n",
        "\n",
        "#frame_SSIM_MLEM, placeholder = calculate_metric(MLEM_output, image_tensor, SSIM, dataframe = True, label='MLEM, SSIM')\n",
        "#frame_MSE_MLEM, placeholder =  calculate_metric(MLEM_output, image_tensor, MSE, dataframe = True, label='MLEM, MSE')\n",
        "#print('################### MLEM ###################')\n",
        "#print(frame_SSIM_MLEM.T)\n",
        "#print(frame_MSE_MLEM.T)\n",
        "\n",
        "break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jkVa95flUdo"
      },
      "source": [
        "## Tuning Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiM_F1KL1cLd"
      },
      "outputs": [],
      "source": [
        "#################\n",
        "## Set Options ##\n",
        "#################\n",
        "\n",
        "tune_exp_name=\"/content/drive/MyDrive/Colab/Working/searches/search-fullSet-highCountSino2actMap-tunedSSIM-AugmentSI\"\n",
        "save_fig=True\n",
        "\n",
        "titlesize=13\n",
        "fontsize=12\n",
        "ticksize=10\n",
        "dpi=800\n",
        "figsize=(10,8)\n",
        "\n",
        "fig = plt.figure(figsize=figsize, dpi=dpi)\n",
        "gs = gridspec.GridSpec(ncols=100, nrows=100)\n",
        "\n",
        "# Top Row Axes #\n",
        "ax1 = fig.add_subplot(gs[0:25,   0:100])\n",
        "ax2 = fig.add_subplot(gs[38:62,   0:100])\n",
        "#ax3 = fig.add_subplot(gs[75:100,  0:100])\n",
        "\n",
        "\n",
        "## Plots ###\n",
        "\n",
        "#refresh_repo(IN_COLAB, local_repo_path=local_repo_dirPath)\n",
        "\n",
        "result_grid, bestResult_logDir = PlotFrame(paths, tune_exp_name, ax1, 'batch_step', 'Batch Step', 'MSE', 'MSE', ylim=(50,20000), logy=True)\n",
        "ax1.set_title('(A) MSE Learning Curves', fontsize=titlesize)\n",
        "\n",
        "result_grid, bestResult_logDir = PlotFrame(paths, tune_exp_name, ax2, 'batch_step', 'Batch Step', 'SSIM', 'SSIM', ylim=(0,1), logy=False)\n",
        "ax2.set_title('(B) SSIM Learning Curves', fontsize=titlesize)\n",
        "\n",
        "#result_grid, bestResult_logDir = PlotFrame(paths, tune_exp_name, ax3, 'batch_step', 'Batch Step', 'CUSTOM', 'Local Distributions Metric', ylim=(300,500))\n",
        "#ax3.set_title('(A) LDM Learning Curves', fontsize=titlesize)\n",
        "\n",
        "# Best Result #\n",
        "\n",
        "#print(bestResult_logdir)\n",
        "\n",
        "# Save Fig? #\n",
        "\n",
        "if save_fig:\n",
        "    plot_save_name='figure-tuning'\n",
        "    savefig(os.path.join(paths['plot_dirPath'], plot_save_name+'.svg'), bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-RDucbz-NOi"
      },
      "source": [
        "## Tune Frame Scatter Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sPXBVEODKlR"
      },
      "outputs": [],
      "source": [
        "print(paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hW_RJkIi-XaT"
      },
      "outputs": [],
      "source": [
        "\n",
        "tune_csv_file = 'frame-tunedMSE-ASHA'\n",
        "\n",
        "\n",
        "tune_dataframe = pd.read_csv(os.path.join(paths['tune_dataframe_dirPath'], tune_csv_file+'.csv'))\n",
        "\n",
        "## Describe Dataframes ##\n",
        "\n",
        "#plt.scatter(tune_dataframe['num_params'], tune_dataframe['mean_CNN_MSE'])\n",
        "#plt.scatter(tune_dataframe['num_params'][1:], tune_dataframe['mean_CNN_MSE'][1:])\n",
        "\n",
        "tune_dataframe.plot.scatter('num_params', 'mean_CNN_MSE', ylim=(0,5))\n",
        "tune_dataframe.plot.scatter('gen_lr', 'mean_CNN_MSE', ylim=(0,5))\n",
        "tune_dataframe.plot.scatter('batch_size', 'mean_CNN_MSE', ylim=(0,5))\n",
        "\n",
        "'''\n",
        "plt.scatter(tune_dataframe['num_params'], tune_dataframe['mean_CNN_MSE'], ylim=(0,1))\n",
        "plt.xlabel('Number of Parameters')\n",
        "plt.ylabel('MSE')\n",
        "plt.show()\n",
        "'''\n",
        "\n",
        "tune_dataframe.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFWg1RoN4NVJ"
      },
      "source": [
        "## Load: Test Dataframes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mMOMILr4NAr"
      },
      "outputs": [],
      "source": [
        "# tunedMSE #\n",
        "test_dataframe_dirPath1= '/content/drive/MyDrive/Colab/Working/Dataframes-TestOnFull'\n",
        "#test_csv_file1 = 'combined-tunedFullMSE-trainedFull-onTrainingSet-noMLEM'   # Use this dataframe to determine thresholds for sorting training set by metrics\n",
        "#test_csv_file1 = 'combined-tunedFullMSE-trainedFull-onTestSet-wMLEM'       # Use this dataframe to determine thresholds for sorting test set by metrics\n",
        "#test_csv_file1 = 'combined-tunedFullSSIM-trainedFull-onTestSet-wMLEM'\n",
        "test_csv_file1 = 'combined-tunedHighMSE-trainedHighMSE-onTestSet-wMLEM'\n",
        "\n",
        "#test_dataframe_dirPath2= '/content/drive/MyDrive/Colab/Working/Dataframes-Test-Quartile-MSE'\n",
        "#test_dataframe_dirPath2= '/content/drive/MyDrive/Colab/Working/Dataframes-TestOnFull'\n",
        "#test_csv_file2 = 'combined-tunedFullSSIM-trainedFull-onTestSet-wMLEM'\n",
        "#test_csv_file2 = 'combined-tunedHighMSE-trainedHighMSE-onTestSet-wMLEM'\n",
        "test_csv_file2 = 'combined-tunedLowSSIM-trainedLowSSIM-onTestSet-wMLEM'\n",
        "\n",
        "# Read Dataframes from File #\n",
        "dataframe_path1 = os.path.join(test_dataframe_dirPath1, test_csv_file1+'.csv')\n",
        "dataframe1 = pd.read_csv(dataframe_path1)\n",
        "dataframe_path2 = os.path.join(test_dataframe_dirPath2, test_csv_file2+'.csv')\n",
        "dataframe2 = pd.read_csv(dataframe_path2)v\n",
        "\n",
        "## Describe Dataframes ##\n",
        "\n",
        "#frame_picked = dataframe[dataframe[\"SSIM (ML-EM)\"]>dataframe[\"SSIM (FBP)\"]]\n",
        "#frame_picked = dataframe[dataframe[\"SSIM (Network)\"]>dataframe[\"SSIM (ML-EM)\"]]\n",
        "\n",
        "#frame_picked = dataframe[dataframe[\"MSE (Network)\"]<dataframe[\"MSE (ML-EM)\"]]\n",
        "#frame_picked = dataframe[dataframe[\"MSE (ML-EM)\"]<dataframe[\"MSE (FBP)\"]]\n",
        "\n",
        "#frame_picked = dataframe1[dataframe1[\"MSE (FBP)\"]>0.95908]\n",
        "#frame_picked = dataframe1[dataframe1[\"MSE (FBP)\"]<0.330922]\n",
        "frame_picked = dataframe1[dataframe1[\"SSIM (FBP)\"]<0.837850]\n",
        "\n",
        "#dataframe1.describe()\n",
        "dataframe2.describe()\n",
        "#frame_picked.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAmVEnJChNGK"
      },
      "source": [
        "### Plot Test Dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJbGBeJbKYt7"
      },
      "outputs": [],
      "source": [
        "## Specify Plotting Parameters ##\n",
        "plot_type = 2 # 1 = histograms, 2 = bin plots, 3 = both\n",
        "\n",
        "column_MSE_1 = 'MSE (ML-EM)'\n",
        "#column_MSE_1 = 'MSE (FBP)'\n",
        "column_MSE_2 = 'MSE (Network)'\n",
        "#column_MSE_2 = 'MSE (FBP)'\n",
        "\n",
        "column_SSIM_1 = 'SSIM (ML-EM)'\n",
        "#column_SSIM_1 = 'SSIM (FBP)'\n",
        "column_SSIM_2 = 'SSIM (Network)'\n",
        "#column_SSIM_2 = 'SSIM (FBP)'\n",
        "\n",
        "\n",
        "titlesize=12\n",
        "fontsize=9\n",
        "ticksize=7\n",
        "dpi=800\n",
        "\n",
        "if plot_type == 1 or plot_type == 2:\n",
        "    figsize=(8,6) # 17,5\n",
        "    fig = plt.figure(figsize=figsize, dpi=dpi)\n",
        "    gs = gridspec.GridSpec(ncols=100, nrows=100)\n",
        "\n",
        "    # Top Row Axes #\n",
        "    ax1 = fig.add_subplot(gs[0:42,   0:43])\n",
        "    ax2 = fig.add_subplot(gs[0:42,   57:100])\n",
        "\n",
        "    # Bottom Row Axes #\n",
        "    ax3 = fig.add_subplot(gs[58:100, 0:43])\n",
        "    ax4 = fig.add_subplot(gs[58:100, 57:100])\n",
        "\n",
        "    if plot_type == 1:\n",
        "        plot_hist_1D(ax1, dataframe1, '(1) CNN-A: MSE Histogram',  'MSE', 'frequency', column_MSE_1 , column_MSE_2, xlim=(0,4), ylim=(0,5000), bins=40)\n",
        "        plot_hist_1D(ax2, dataframe1, '(2) CNN-A: SSIM Histogram', 'SSIM','frequency', column_SSIM_1, column_SSIM_2, xlim=(0.6,1), ylim=(0,4000), bins=40)\n",
        "        plot_hist_1D(ax3, dataframe2, '(3) CNN-B: MSE Histogram',  'MSE', 'frequency', column_MSE_1 , column_MSE_2,  xlim=(0,4), ylim=(0,5000),  bins=40)\n",
        "        plot_hist_1D(ax4, dataframe2, '(4) CNN-B: SSIM Histogram', 'SSIM','frequency', column_SSIM_1, column_SSIM_2, xlim=(0.6,1), ylim=(0,4000), bins=40)\n",
        "    if plot_type == 2:\n",
        "        plot_hist_2D(ax1, dataframe1, '(1) CNN-A: MSE Bin Plot', column_MSE_1, 'MSE (CNN-A)', column_MSE_1 , column_MSE_2,(0,1.5), (0,1.5), gridsize=60)\n",
        "        plot_hist_2D(ax2, dataframe1, '(2) CNN-A: SSIM Bin Plot',column_SSIM_1, 'SSIM (CNN-A)', column_SSIM_1, column_SSIM_2, (.7,1), (.7,1), gridsize=100)\n",
        "        plot_hist_2D(ax3, dataframe2, '(3) CNN-B: MSE Bin Plot', column_MSE_1, 'MSE (CNN-B)', column_MSE_1 , column_MSE_2, (0,1.5), (0,1.5), gridsize=60)\n",
        "        plot_hist_2D(ax4, dataframe2, '(4) CNN-B: SSIM Bin Plot', column_SSIM_1, 'SSIM (CNN-B)', column_SSIM_1, column_SSIM_2, (.7,1), (.7,1), gridsize=100)\n",
        "\n",
        "if plot_type == 3:\n",
        "    figsize=(15,6) # 17,5\n",
        "    fig = plt.figure(figsize=figsize, dpi=dpi)\n",
        "    gs = gridspec.GridSpec(ncols=100, nrows=100)\n",
        "\n",
        "    # Top Row Axes #\n",
        "    ax1 = fig.add_subplot(gs[0:42,   0:18]) # 20\n",
        "    ax2 = fig.add_subplot(gs[0:42,   25:47]) # 22\n",
        "    ax3 = fig.add_subplot(gs[0:42,   53:74]) # 20\n",
        "    ax4 = fig.add_subplot(gs[0:42,   80:100]) # 22\n",
        "\n",
        "    # Bottom Row Axes #\n",
        "    ax5 = fig.add_subplot(gs[58:100, 0:18]) # -5-\n",
        "    ax6 = fig.add_subplot(gs[58:100, 25:47]) # -3 - -3-\n",
        "    ax7 = fig.add_subplot(gs[58:100, 53:74]) # -5-\n",
        "    ax8 = fig.add_subplot(gs[58:100, 80:100])\n",
        "\n",
        "    plot_hist_1D(ax1, dataframe1, '(1) CNN-A: MSE Histogram',  'MSE', 'frequency', column_MSE_1 , column_MSE_2, xlim=(0,4), ylim=(0,5000), bins=40)\n",
        "    plot_hist_1D(ax2, dataframe1, '(3) CNN-A: SSIM Histogram', 'SSIM','frequency', column_SSIM_1, column_SSIM_2, xlim=(0.6,1), ylim=(0,4000), bins=40)\n",
        "    plot_hist_2D(ax3, dataframe1, '(5) CNN-A: MSE Bin Plot', column_MSE_1, 'MSE (CNN-A)', column_MSE_1 , column_MSE_2,(0,1.5), (0,1.5), gridsize=60)\n",
        "    plot_hist_2D(ax4, dataframe1, '(7) CNN-A: SSIM Bin Plot',column_SSIM_1, 'SSIM (CNN-A)', column_SSIM_1, column_SSIM_2, (.7,1), (.7,1), gridsize=100)\n",
        "\n",
        "    plot_hist_1D(ax5, dataframe2, '(2) CNN-B: MSE Histogram',  'MSE', 'frequency', column_MSE_1 , column_MSE_2,  xlim=(0,4), ylim=(0,5000),  bins=40)\n",
        "    plot_hist_1D(ax6, dataframe2, '(4) CNN-B: SSIM Histogram', 'SSIM','frequency', column_SSIM_1, column_SSIM_2, xlim=(0.6,1), ylim=(0,4000), bins=40)\n",
        "    plot_hist_2D(ax7, dataframe2, '(6) CNN-B: MSE Bin Plot', column_MSE_1, 'MSE (CNN-B)', column_MSE_1 , column_MSE_2, (0,1.5), (0,1.5), gridsize=60)\n",
        "    plot_hist_2D(ax8, dataframe2, '(8) CNN-B: SSIM Bin Plot', column_SSIM_1, 'SSIM (CNN-B)', column_SSIM_1, column_SSIM_2, (.7,1), (.7,1), gridsize=100)\n",
        "\n",
        "save_path = plot_dir+'figure-histograms.png'\n",
        "savefig(save_path, bbox_inches='tight')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Alter Dataset"
      ],
      "metadata": {
        "id": "lfTfEgU5cZQl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Precompute Attenuation Sinograms"
      ],
      "metadata": {
        "id": "MlNqa1M59MLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "precompute=True\n",
        "\n",
        "#atten_image_fileName = 'train-attenMap.npy'\n",
        "#atten_sino_fileName = 'train-attenSino-382x513.npy'\n",
        "atten_image_fileName = 'test-attenMap.npy'\n",
        "atten_sino_fileName = 'test-attenSino-382x513.npy'\n",
        "\n",
        "\n",
        "if precompute:\n",
        "    precompute_atten_sinos(\n",
        "        project_dirPath,\n",
        "        data_dirName,\n",
        "        atten_image_fileName,\n",
        "        atten_sino_fileName,\n",
        "        sino_height=382,\n",
        "        sino_width=512,\n",
        "        theta_type='symmetrical',\n",
        "        atten_creation_pool_size=2,\n",
        "        circle=False,\n",
        "    )"
      ],
      "metadata": {
        "id": "FmVi-LjT9Omz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-tDENcFyMMC"
      },
      "source": [
        "## Sort: Dataset by Metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2q2L7hFyQ1d"
      },
      "outputs": [],
      "source": [
        "## Changeable Variables ##\n",
        "\n",
        "load_sino_path = '/content/drive/MyDrive/Repository/PET_Data/train_sino-70k.npy'\n",
        "load_image_path = '/content/drive/MyDrive/Repository/PET_Data/train_image-70k.npy'\n",
        "save_sino_path = '/content/drive/MyDrive/Repository/PET_Data/quartile_data/train_sino-lowSSIM-17500.npy'\n",
        "save_image_path = '/content/drive/MyDrive/Repository/PET_Data/quartile_data/train_image-lowSSIM-17500.npy'\n",
        "'''\n",
        "metric_function = MSE\n",
        "max_save_index = 17500\n",
        "threshold = 0.330922\n",
        "threshold_min_max = 'min'\n",
        "'''\n",
        "metric_function = SSIM\n",
        "max_save_index = 17500\n",
        "threshold = 0.837850 #0.837850  # MSE (min): 0.330922, SSIM (max): 0.837850\n",
        "threshold_min_max = 'max'\n",
        "\n",
        "## Run & Verify Result ##\n",
        "save_sino_array, save_image_array = sort_DataSet(config, load_image_path, load_sino_path, save_image_path, save_sino_path, max_save_index,\n",
        "                                                 metric_function, threshold, threshold_min_max=threshold_min_max, num_examples=-1, visualize=False, sino_scale=sino_scale)\n",
        "\n",
        "sino_ground_scaled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwU5ioxR6bHg"
      },
      "source": [
        "## Sort: Check & Save"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQCMCuDx6bEp"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTrqg3MHNl1x"
      },
      "outputs": [],
      "source": [
        "#save_sino_path = '/content/drive/MyDrive/Repository/PET_Data/quartile_data/train_sino-lowSSIM-17500.npy'\n",
        "#save_image_path = '/content/drive/MyDrive/Repository/PET_Data/quartile_data/train_sino-lowSSIM-17500.npy'\n",
        "\n",
        "# Print sorted array shape & display a few images #\n",
        "print('save_sino_array.shape: ', save_sino_array.shape)\n",
        "print('save_image_array.shape: ', save_image_array.shape)\n",
        "\n",
        "print('save_sino_array sample images')\n",
        "print('save_image_array sample images')\n",
        "show_multiple_matched_tensors(torch.from_numpy(save_sino_array[500:509]))\n",
        "show_multiple_matched_tensors(torch.from_numpy(save_image_array[500:509]))\n",
        "\n",
        "\n",
        "# Save the sorted array to disk #\n",
        "save_sino_array.flush()\n",
        "save_image_array.flush()\n",
        "#np.save(save_sino_path, save_sino_array)\n",
        "#np.save(save_image_path, save_image_array)\n",
        "\n",
        "# Load the saved array and make sure it's the same size/has the same images #\n",
        "load_sino_array = np.load(save_sino_path, mmap_mode='r')\n",
        "load_image_array = np.load(save_image_path, mmap_mode='r')\n",
        "print('load_sino_array.shape: ', load_sino_array.shape)\n",
        "print('load_image_array.shape: ', load_image_array.shape)\n",
        "\n",
        "print('load_sino_array sample images')\n",
        "print('load_image_array sample images')\n",
        "show_multiple_matched_tensors(torch.from_numpy(load_sino_array[500:509]))\n",
        "show_multiple_matched_tensors(torch.from_numpy(load_image_array[500:509]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0S2M7PagXsv"
      },
      "source": [
        "# Experimenting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23TOba33L4qf"
      },
      "outputs": [],
      "source": [
        "## Find what GPU I'm using ##\n",
        "import torch\n",
        "print(torch.cuda.is_available())  # Should be True\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3anZSZqZgJs"
      },
      "source": [
        "# Notes:\n",
        "Change next\n",
        "===========\n",
        "Change out HyperOpt search for Optuna\n",
        "Install Git on home machine: https://git-scm.com/install/windows\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "For high/low MSE experiments\n",
        "============================\n",
        "-Tuned networks for 180 minutes each.\n",
        "\n",
        "-Trained for 100 epochs using on-the-fly augmentation\n",
        "\n",
        "-See notes in checkpoint folder\n",
        "\n",
        "\n",
        "For LDM, window = 5, stride = 2\n",
        "===============================\n",
        "tune_max_t = 20            \n",
        "\n",
        "tune_minutes = 180      \n",
        "\n",
        "tune_batches_per_report=12    \n",
        "\n",
        "tune_augment=False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AHpRBHQKzo9"
      },
      "source": [
        "Tensor board works for all experiments except the last one.\n",
        "My plotting function no longer works for any of the experiments."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}