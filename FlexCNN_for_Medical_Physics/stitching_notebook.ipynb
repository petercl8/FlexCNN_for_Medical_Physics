{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8gBjOYeJpAJ"
   },
   "source": [
    "# Notes: changed\n",
    "\n",
    "This code can perform the following tasks:\n",
    "\n",
    "\n",
    "*   Tune a CNN to directly reconstruct PET images from Sinograms (find a set of hyperparameters)\n",
    "*   Train a network with a given set of hyperparameters\n",
    "*   Test the network and record MSE and SSIM values for each image tested\n",
    "*   Visualize the data and test results\n",
    "*   Plot training curves, metric histograms, example images\n",
    "\n",
    "The code is organized into sections. The important sections that you can edit are:\n",
    "\n",
    "\n",
    "> **User Parameters** - Edit important user parameters and decide what the code will do\n",
    "\n",
    "> **Configuration Dicts: Supervisory** - Dictionary for supervised learning. Make sure this matches the CNN loaded by the checkpoint file, if you are loading from a checkpoint.\n",
    "\n",
    "In addition to these, you may find that running a single cell is useful when all variables/classes/files have been loaded into memory. This can be quicker than running everything from scratch.\n",
    "\n",
    "The cells nested under **Analysis Functions** each have their own changeable parameters.\n",
    "\n",
    "*Notes:*\n",
    "\n",
    "*1) Raytune in particular is constantly changing. Therefore, if you are running this code after the authors have ceased maintaining it and there are errors, these are likely due to RayTune classes, methods, or functions being changed. Unfortunately, these seem to happen on a regular basis, as the code is relatively new.*\n",
    "\n",
    "*2) This code was originally written to tune/train/test not just sinogram to image supervisory networks (sinogram-->image), but also image to sinogram supervisory networks, GANs, CycleGANs, and Cycle + Supervisory networks. These latter capabilities have not been updated, but much of the code survives for this functionality. In the future, the code may be updated once again have these capabilities.*\n",
    "\n",
    "\n",
    "GPUs\n",
    "====\n",
    "From best to worst:\n",
    "\n",
    "V100 - 6.92/hr\n",
    "\n",
    "L4 - 2.15/hr\n",
    "\n",
    "T4 - 1.7/hr\n",
    "\n",
    "v6e-1 TPU - 4.21/hr\n",
    "\n",
    "v5e-1 TPU - 4.11/hr\n",
    "\n",
    "v2-8 TPU - 1.82/hr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsbxljN96QMU"
   },
   "source": [
    "# User Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUTAEh3CDd0A"
   },
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDx4D3QNDjan"
   },
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7C3ZYnMDoa5"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZGwlOGCDpj-"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-AVXtlTSDqhl"
   },
   "source": [
    "## Visualizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jdfEsglDIfJ3"
   },
   "source": [
    "# Setup Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TOlPJH8MGx21"
   },
   "outputs": [],
   "source": [
    "import os, sys, glob, importlib, inspect, types, subprocess, pkgutil\n",
    "\n",
    "def sense_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        IN_COLAB = True\n",
    "    except ImportError:\n",
    "        IN_COLAB = False\n",
    "    return IN_COLAB\n",
    "\n",
    "def sense_device(device='sense'):\n",
    "    if device == 'sense':\n",
    "        if torch.cuda.is_available():\n",
    "            device = 'cuda'\n",
    "        else:\n",
    "            device = 'cpu'\n",
    "    elif device == 'cpu':\n",
    "        device = 'cpu'\n",
    "    elif device == 'cuda':\n",
    "        device = 'cuda'\n",
    "    return device\n",
    "\n",
    "def install_required_packages_ray_version(IN_COLAB, force_reinstall=False, include_optional=True, ray_version=None):\n",
    "    \"\"\"\n",
    "    Installs required Python packages efficiently.\n",
    "    - Detects if running in Colab or locally.\n",
    "    - Installs missing packages only (unless force_reinstall=True).\n",
    "    - Ensures Ray Tune dependencies are installed even if ray is already present.\n",
    "    - Can pin Ray version with ray_version (e.g., \"1.12.0\").\n",
    "    \"\"\"\n",
    "\n",
    "    # Base list of packages\n",
    "    packages = [\n",
    "        \"torch\", \"torchvision\", \"torchaudio\",\n",
    "        \"ray[tune]\", \"tensorboardX\", \"hyperopt\",\n",
    "        \"numpy\", \"pandas\", \"matplotlib\",\n",
    "        \"scikit-image\", \"scipy\"\n",
    "    ]\n",
    "\n",
    "    # Optional packages for visualization\n",
    "    optional_packages = [\"tensorboard\"]\n",
    "    widgets_packages = [\"ipywidgets\"]\n",
    "    missing = []\n",
    "\n",
    "    for pkg in packages:\n",
    "        pkg_name = pkg.split(\"[\")[0]\n",
    "\n",
    "        # Special handling for Ray Tune\n",
    "        if pkg_name == \"ray\":\n",
    "            try:\n",
    "                import ray\n",
    "                import ray.tune\n",
    "                ray_tune_installed = True\n",
    "            except ImportError:\n",
    "                ray_tune_installed = False\n",
    "\n",
    "            # Build the package name with version if specified\n",
    "            if ray_version:\n",
    "                pkg = f\"ray[{ 'tune' if 'tune' in pkg else ''}]=={ray_version}\"\n",
    "\n",
    "            if force_reinstall or not ray_tune_installed:\n",
    "                missing.append(pkg)\n",
    "            continue\n",
    "\n",
    "        # General case\n",
    "        if importlib.util.find_spec(pkg_name) is None or force_reinstall:\n",
    "            missing.append(pkg)\n",
    "\n",
    "    # Optionally add optional packages\n",
    "    if include_optional:\n",
    "        missing += optional_packages + widgets_packages\n",
    "\n",
    "    if not missing:\n",
    "        print(\"âœ… All required packages already installed.\")\n",
    "        return\n",
    "\n",
    "    print(f\"ðŸ“¦ Installing missing packages: {', '.join(missing)}\")\n",
    "\n",
    "    # Build pip command\n",
    "    if IN_COLAB:\n",
    "        cmd = [\"pip\", \"install\", \"--upgrade\"] + missing\n",
    "    else:\n",
    "        cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\"] + missing\n",
    "\n",
    "    try:\n",
    "        subprocess.check_call(cmd)\n",
    "        print(\"âœ… Installation complete.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ Installation failed: {e}\")\n",
    "\n",
    "def install_required_packages_forceGPU(IN_COLAB=True, force_reinstall=False, include_optional=True):\n",
    "    \"\"\"\n",
    "    Installs required Python packages efficiently.\n",
    "    - Detects if running in Colab or locally.\n",
    "    - Installs missing packages only (unless force_reinstall=True).\n",
    "    - Automatically installs GPU-enabled PyTorch if a CUDA-capable GPU is detected.\n",
    "    \"\"\"\n",
    "\n",
    "    # Base list of non-PyTorch packages\n",
    "    other_packages = [\n",
    "        \"ray[tune]\", \"tensorboardX\", \"hyperopt\",\n",
    "        \"numpy\", \"pandas\", \"matplotlib\",\n",
    "        \"scikit-image\", \"scipy\"\n",
    "    ]\n",
    "\n",
    "    # Optional packages\n",
    "    optional_packages = [\"tensorboard\"]\n",
    "    widgets_packages = [\"ipywidgets\"]\n",
    "\n",
    "    missing = []\n",
    "\n",
    "    # ------------------------------\n",
    "    # PyTorch: detect CPU vs GPU\n",
    "    # ------------------------------\n",
    "    torch_packages = [\"torch\", \"torchvision\", \"torchaudio\"]\n",
    "    pip_index_url = []\n",
    "\n",
    "    cuda_available = False\n",
    "    try:\n",
    "        import torch\n",
    "        cuda_available = torch.cuda.is_available()\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "    if not IN_COLAB and not cuda_available:\n",
    "        # Check GPU presence on Windows via nvidia-smi\n",
    "        try:\n",
    "            gpu_info = subprocess.check_output(\"nvidia-smi\", shell=True).decode()\n",
    "            if \"failed\" not in gpu_info.lower():\n",
    "                cuda_available = True\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # If local GPU detected, uninstall CPU-only PyTorch first and set CUDA URL\n",
    "    if cuda_available and not IN_COLAB:\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"torch\", \"torchvision\", \"torchaudio\"])\n",
    "        except subprocess.CalledProcessError:\n",
    "            # Ignore if PyTorch is not installed\n",
    "            pass\n",
    "        pip_index_url = [\"--index-url\", \"https://download.pytorch.org/whl/cu124\"]\n",
    "\n",
    "    # ------------------------------\n",
    "    # Check other packages\n",
    "    # ------------------------------\n",
    "    for pkg in other_packages:\n",
    "        pkg_name = pkg.split(\"[\")[0]\n",
    "        if pkg_name == \"ray\":\n",
    "            try:\n",
    "                import ray\n",
    "                import ray.tune\n",
    "                ray_tune_installed = True\n",
    "            except ImportError:\n",
    "                ray_tune_installed = False\n",
    "            if force_reinstall or not ray_tune_installed:\n",
    "                missing.append(pkg)\n",
    "            continue\n",
    "\n",
    "        if importlib.util.find_spec(pkg_name) is None or force_reinstall:\n",
    "            missing.append(pkg)\n",
    "\n",
    "    # Add optional packages\n",
    "    if include_optional:\n",
    "        missing += optional_packages + widgets_packages\n",
    "\n",
    "    # Remove duplicates\n",
    "    missing = list(dict.fromkeys(missing))\n",
    "\n",
    "    if not missing and not force_reinstall:\n",
    "        print(\"âœ… All required packages already installed.\")\n",
    "        return\n",
    "\n",
    "    print(f\"ðŸ“¦ Installing missing packages: {', '.join(torch_packages + missing)}\")\n",
    "\n",
    "    # ------------------------------\n",
    "    # Build pip command\n",
    "    # ------------------------------\n",
    "    if IN_COLAB:\n",
    "        cmd = [\"pip\", \"install\", \"--upgrade\"] + torch_packages + missing + pip_index_url\n",
    "    else:\n",
    "        cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\"] + torch_packages + missing + pip_index_url\n",
    "\n",
    "    # ------------------------------\n",
    "    # Run pip install\n",
    "    # ------------------------------\n",
    "    try:\n",
    "        subprocess.check_call(cmd)\n",
    "        print(\"âœ… Installation complete.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ Installation failed: {e}\")\n",
    "\n",
    "    # ------------------------------\n",
    "    # Confirm CUDA availability\n",
    "    # ------------------------------\n",
    "    try:\n",
    "        import torch\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"âœ… PyTorch CUDA detected: {torch.cuda.get_device_name(0)}\")\n",
    "        else:\n",
    "            print(\"âš ï¸ PyTorch installed, but no GPU detected. Using CPU-only build.\")\n",
    "    except ImportError:\n",
    "        print(\"âŒ PyTorch installation failed completely.\")\n",
    "\n",
    "def install_required_packages(IN_COLAB=True, force_reinstall=False, include_optional=True):\n",
    "    \"\"\"\n",
    "    Installs required Python packages efficiently.\n",
    "    - Detects if running in Colab or locally.\n",
    "    - Installs missing packages only (unless force_reinstall=True).\n",
    "    - Ensures Ray Tune dependencies are installed even if ray is already present.\n",
    "    \"\"\"\n",
    "\n",
    "    # Base list of packages\n",
    "    packages = [\n",
    "        \"torch\", \"torchvision\", \"torchaudio\",\n",
    "        \"ray[tune]\", \"tensorboardX\", \"hyperopt\",\n",
    "        \"numpy\", \"pandas\", \"matplotlib\",\n",
    "        \"scikit-image\", \"scipy\"\n",
    "    ]\n",
    "\n",
    "    # Optional packages for visualization\n",
    "    optional_packages = [\"tensorboard\"]\n",
    "    # Widgets for tqdm are optional; plain progress bar is fine\n",
    "    widgets_packages = [\"ipywidgets\"]\n",
    "    missing = []\n",
    "\n",
    "    for pkg in packages:\n",
    "        pkg_name = pkg.split(\"[\")[0]\n",
    "\n",
    "        # Special handling for Ray Tune\n",
    "        if pkg_name == \"ray\":\n",
    "            try:\n",
    "                import ray\n",
    "                import ray.tune\n",
    "                ray_tune_installed = True\n",
    "            except ImportError:\n",
    "                ray_tune_installed = False\n",
    "            if force_reinstall or not ray_tune_installed:\n",
    "                missing.append(pkg)\n",
    "            continue\n",
    "\n",
    "        # General case\n",
    "        if importlib.util.find_spec(pkg_name) is None or force_reinstall:\n",
    "            missing.append(pkg)\n",
    "\n",
    "    # Optionally add optional packages\n",
    "    if include_optional:\n",
    "        missing += optional_packages + widgets_packages\n",
    "\n",
    "    if not missing:\n",
    "        print(\"âœ… All required packages already installed.\")\n",
    "        return\n",
    "\n",
    "    print(f\"ðŸ“¦ Installing missing packages: {', '.join(missing)}\")\n",
    "\n",
    "    # Build pip command\n",
    "    if IN_COLAB:\n",
    "        cmd = [\"pip\", \"install\", \"--upgrade\"] + missing\n",
    "    else:\n",
    "        cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\"] + missing\n",
    "\n",
    "    try:\n",
    "        subprocess.check_call(cmd)\n",
    "        print(\"âœ… Installation complete.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ Installation failed: {e}\")\n",
    "\n",
    "def refresh_repo(\n",
    "    IN_COLAB = True,\n",
    "    repo_name: str = \"FlexCNN_for_Medical_Physics\",\n",
    "    github_username: str = \"petercl8\",\n",
    "    local_repo_path: str = None,\n",
    "    auto_import: bool = True,\n",
    "    verbose: bool = True):\n",
    "    \"\"\"\n",
    "    Clone/pull and install the repo, then optionally auto-import all modules.\n",
    "    Also reloads all submodules to reflect changes without restarting the runtime.\n",
    "    \"\"\"\n",
    "    # --- Determine base directory ---\n",
    "    base_dir = \"/content\" if IN_COLAB else local_repo_path\n",
    "    if base_dir is None:\n",
    "        raise ValueError(\"local_repo_path must be provided if not in Colab\")\n",
    "\n",
    "    repo_path = os.path.join(base_dir, repo_name)\n",
    "    repo_url = (\n",
    "        f\"https://github.com/{github_username}/{repo_name}.git\"\n",
    "        if IN_COLAB\n",
    "        else f\"git@github.com:{github_username}/{repo_name}.git\"\n",
    "    )\n",
    "\n",
    "    # --- Clone or update ---\n",
    "    if not os.path.exists(repo_path):\n",
    "        if verbose:\n",
    "            print(f\"ðŸ“¦ Cloning {repo_name} into {base_dir}...\")\n",
    "        subprocess.run([\"git\", \"clone\", repo_url], cwd=base_dir, check=True)\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(f\"ðŸ”„ Pulling latest changes in {repo_path}...\")\n",
    "        subprocess.run([\"git\", \"pull\"], cwd=repo_path, check=True)\n",
    "\n",
    "    # --- Install package in editable mode ---\n",
    "    if verbose:\n",
    "        print(\"âš™ï¸ Installing the package in editable mode...\")\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \".\"],\n",
    "                   cwd=repo_path, check=True)\n",
    "\n",
    "    # --- Ensure repo path is importable ---\n",
    "    if repo_path not in sys.path:\n",
    "        sys.path.insert(0, repo_path)\n",
    "\n",
    "    # --- Import the package ---\n",
    "    package = importlib.import_module(repo_name)\n",
    "\n",
    "    # --- Reload all submodules recursively ---\n",
    "    def reload_submodules(pkg):\n",
    "        for _, modname, ispkg in pkgutil.walk_packages(pkg.__path__, pkg.__name__ + \".\"):\n",
    "            if modname in sys.modules:\n",
    "                importlib.reload(sys.modules[modname])\n",
    "            else:\n",
    "                importlib.import_module(modname)\n",
    "        importlib.reload(pkg)\n",
    "\n",
    "    reload_submodules(package)\n",
    "\n",
    "    # --- Gather all symbols ---\n",
    "    imported = {}\n",
    "    for _, modname, ispkg in pkgutil.walk_packages(package.__path__, package.__name__ + \".\"):\n",
    "        mod = importlib.import_module(modname)\n",
    "        for name, obj in inspect.getmembers(mod):\n",
    "            if not name.startswith(\"_\"):\n",
    "                imported[name] = obj\n",
    "\n",
    "    # --- Inject symbols into caller's globals if requested ---\n",
    "    if auto_import:\n",
    "        if verbose:\n",
    "            print(\"âœ¨ Injecting all symbols into global namespace...\")\n",
    "        caller_globals = inspect.stack()[1].frame.f_globals\n",
    "        caller_globals.update(imported)\n",
    "        if verbose:\n",
    "            print(f\"âœ… Setup complete: {len(imported)} symbols loaded into globals.\")\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(f\"âœ… Imported {len(imported)} symbols (not injected).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KpYLqzIhkzYt",
    "outputId": "7ef05ecc-8156-4242-fbd1-262fe6b3b4ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Installing missing packages: ray[tune], tensorboardX, scikit-image, tensorboard, ipywidgets\n",
      "âœ… Installation complete.\n"
     ]
    }
   ],
   "source": [
    "# --- Sense environment ---\n",
    "IN_COLAB = sense_colab()\n",
    "\n",
    "# --- Install packages and import ---\n",
    "install_required_packages(IN_COLAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hVzkxW7J6xlO",
    "outputId": "9be582e7-8bc1-4074-e08a-ef179d3d44a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Pulling latest changes in /content/FlexCNN_for_Medical_Physics...\n",
      "âš™ï¸ Installing the package in editable mode...\n",
      "âœ¨ Injecting all symbols into global namespace...\n",
      "âœ… Setup complete: 135 symbols loaded into globals.\n",
      "CPUs available: 12\n",
      "GPUs available: 1\n",
      "  GPU 0: NVIDIA L4\n",
      "Mounted at /content/drive\n",
      "placeholder\n"
     ]
    }
   ],
   "source": [
    "# --- Refresh Repository ---\n",
    "refresh_repo(IN_COLAB, local_repo_path=local_repo_dirPath)\n",
    "\n",
    "# --- Test Resources ---\n",
    "list_compute_resources()\n",
    "\n",
    "# --- Set main project directory\n",
    "project_dirPath = setup_project_dirs(IN_COLAB, project_local_dirPath, project_colab_dirPath, mount_colab_drive=True)\n",
    "\n",
    "# --- Set Device ---\n",
    "device = sense_device(device=device_opt)\n",
    "\n",
    "# Build grouped parameter dictionaries #\n",
    "\n",
    "common_settings = {\n",
    "    'run_mode': run_mode,\n",
    "    'device': device,\n",
    "    'num_examples': num_examples,\n",
    "}\n",
    "\n",
    "base_dirs = {\n",
    "    'project_dirPath': project_dirPath,\n",
    "    'plot_dirName': plot_dirName,\n",
    "    'checkpoint_dirName': checkpoint_dirName,\n",
    "    'tune_storage_dirName': tune_storage_dirName,\n",
    "    'tune_dataframe_dirName': tune_dataframe_dirName,\n",
    "    'test_dataframe_dirName': test_dataframe_dirName,\n",
    "    'data_dirName': data_dirName\n",
    "}\n",
    "\n",
    "data_files = {\n",
    "    'tune_sino_file': tune_sino_file,\n",
    "    'tune_image_file': tune_image_file,\n",
    "    'train_sino_file': train_sino_file,\n",
    "    'train_image_file': train_image_file,\n",
    "    'test_sino_file': test_sino_file,\n",
    "    'test_image_file': test_image_file\n",
    "}\n",
    "\n",
    "mode_files = {\n",
    "    'tune_csv_file': tune_csv_file,\n",
    "    'train_checkpoint_file': train_checkpoint_file,\n",
    "    'test_checkpoint_file': test_checkpoint_file,\n",
    "    'test_csv_file': test_csv_file,\n",
    "    'visualize_checkpoint_file': visualize_checkpoint_file\n",
    "}\n",
    "\n",
    "network_opts = {\n",
    "    'network_type': network_type,\n",
    "    'train_SI': train_SI,\n",
    "    'image_size': image_size,\n",
    "    'sino_size': sino_size,\n",
    "    'image_channels': image_channels,\n",
    "    'sino_channels': sino_channels,\n",
    "}\n",
    "\n",
    "tune_opts = {\n",
    "    'tune_exp_name': tune_exp_name,\n",
    "    'tune_scheduler': tune_scheduler,\n",
    "    'tune_dataframe_fraction': tune_dataframe_fraction,\n",
    "    'tune_restore': tune_restore,\n",
    "    'tune_max_t': tune_max_t,\n",
    "    'tune_minutes': tune_minutes,\n",
    "    'tune_for': tune_for,\n",
    "    'tune_even_reporting': tune_even_reporting,\n",
    "    'tune_batches_per_report': tune_batches_per_report,\n",
    "    'tune_examples_per_report': tune_examples_per_report,\n",
    "    'tune_augment': tune_augment,\n",
    "    'tune_grace_period': tune_grace_period,\n",
    "    'tune_debug': tune_debug,\n",
    "    'tune_force_fixed_config': tune_force_fixed_config,\n",
    "    'num_CPUs': num_CPUs,\n",
    "    'num_GPUs': num_GPUs,\n",
    "    'cpus_per_trial': CPUs_per_trial,  # per trial\n",
    "    'gpus_per_trial': GPUs_per_trial,  # per trial\n",
    "}\n",
    "\n",
    "train_opts = {\n",
    "    'train_load_state': train_load_state,\n",
    "    'train_save_state': train_save_state,\n",
    "    'training_epochs': train_epochs,\n",
    "    'train_augment': train_augment,\n",
    "    'train_display_step': train_display_step,\n",
    "    'train_sample_division': train_sample_division,\n",
    "    'train_show_times': train_show_times,\n",
    "}\n",
    "\n",
    "test_opts = {\n",
    "    'test_display_step': test_display_step,\n",
    "    'test_batch_size': test_batch_size,\n",
    "    'test_chunk_size': test_chunk_size,\n",
    "    'testset_size': testset_size,\n",
    "    'test_begin_at': test_begin_at,\n",
    "    'test_compute_MLEM': test_compute_MLEM,\n",
    "    'test_set_type': test_set_type,\n",
    "    'test_merge_dataframes': test_merge_dataframes,\n",
    "    'test_show_times': test_show_times,\n",
    "    'test_shuffle': test_sample_division,\n",
    "    'test_sample_division': test_sample_division\n",
    "}\n",
    "\n",
    "viz_opts = {\n",
    "    'visualize_batch_size': visualize_batch_size,\n",
    "    'visualize_offset': visualize_offset,\n",
    "    'visualize_type': visualize_type,\n",
    "    'visualize_shuffle': visualize_shuffle,\n",
    "}\n",
    "\n",
    "# Build paths and settings using new functions\n",
    "paths = setup_paths(\n",
    "    run_mode=run_mode,\n",
    "    base_dirs=base_dirs,\n",
    "    data_files=data_files,\n",
    "    mode_files=mode_files,\n",
    "    test_ops=test_opts,\n",
    "    viz_ops=viz_opts\n",
    ")\n",
    "\n",
    "settings = setup_settings(\n",
    "    run_mode=run_mode,\n",
    "    common_settings=common_settings,\n",
    "    tune_opts=tune_opts,\n",
    "    train_opts=train_opts,\n",
    "    test_opts=test_opts,\n",
    "    viz_opts=viz_opts,\n",
    ")\n",
    "\n",
    "# --- Build Config Dictionary ---\n",
    "config = construct_config(\n",
    "    run_mode=run_mode,\n",
    "    network_opts=network_opts,\n",
    "    test_opts=test_opts,\n",
    "    viz_opts=viz_opts,\n",
    "    config_SUP_SI=config_SUP_SI,\n",
    "    config_SUP_IS=config_SUP_IS,\n",
    "    config_GAN_SI=config_GAN_SI,\n",
    "    config_GAN_IS=config_GAN_IS,\n",
    "    config_CYCLEGAN=config_CYCLEGAN,\n",
    "    config_CYCLESUP=config_CYCLESUP,\n",
    "    config_RAY_SI=config_RAY_SI,\n",
    "    config_RAY_IS=config_RAY_IS,\n",
    "    config_RAY_SUP=config_RAY_SUP,\n",
    "    config_RAY_GAN=config_RAY_GAN,\n",
    "    config_SUP_RAY_cycle=config_SUP_RAY_cycle,\n",
    "    config_GAN_RAY_cycle=config_GAN_RAY_cycle,\n",
    ")\n",
    "\n",
    "tune_exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Oihs2NNMrWP_"
   },
   "outputs": [],
   "source": [
    "\n",
    "from ray import air, tune, train\n",
    "from ray.air import session\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.schedulers import FIFOScheduler # First in/first out scheduler\n",
    "from ray.tune import ResultGrid, JupyterNotebookReporter, CLIReporter\n",
    "from ray.tune.search.hyperopt import HyperOptSearch    # Search Algorithm (current)\n",
    "#from ray.tune.suggest.ax import AxSearch               # Search Algorithm (couldn't make this work)\n",
    "#from ray.tune.suggest.bayesopt import BayesOptSearch   # Search Algorithm (couldn't make this work)\n",
    "\n",
    "# Pytorch ##\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "torch.manual_seed(0)  # For testing purposes\n",
    "\n",
    "## Torchvision ##\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms\n",
    "\n",
    "## Numpy/MatPlotLib ##\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.pyplot import savefig\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "## Pandas ##\n",
    "import pandas as pd\n",
    "\n",
    "## SciKit #\n",
    "from skimage import metrics\n",
    "from skimage.metrics import structural_similarity\n",
    "from skimage.transform import radon, iradon\n",
    "from skimage.transform import iradon\n",
    "from skimage import morphology\n",
    "from skimage.morphology import opening, erosion\n",
    "#from skimage.restoration import denoise_bilateral, denoise_tv_chambolle, denoise_wavelet\n",
    "\n",
    "## SciPy ##\n",
    "#from scipy.stats import moment as compute_moment\n",
    "\n",
    "## Python ##\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "#from IPython.display import display, clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "os7IjqSFkB7B",
    "outputId": "e07064aa-1535-4021-d39a-0f768ebbe0c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-tune check:\n",
      "  num_CPUs: 12\n",
      "  num_GPUs: 1\n",
      "  cpus_per_trial: 2\n",
      "  gpus_per_trial: 1\n",
      "  settings device: cuda\n",
      "  torch.cuda.is_available(): True\n",
      "  CUDA device: NVIDIA L4\n"
     ]
    }
   ],
   "source": [
    "print('Pre-tune check:')\n",
    "print('  num_CPUs:', tune_opts.get('num_CPUs'))\n",
    "print('  num_GPUs:', tune_opts.get('num_GPUs'))\n",
    "print('  cpus_per_trial:', tune_opts.get('cpus_per_trial'))\n",
    "print('  gpus_per_trial:', tune_opts.get('gpus_per_trial'))\n",
    "print('  settings device:', settings['device'])\n",
    "import torch\n",
    "print('  torch.cuda.is_available():', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('  CUDA device:', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tunHHb885PKf"
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J9PCpxBnHo07"
   },
   "outputs": [],
   "source": [
    "# --- Refresh Repository ---\n",
    "#refresh_repo(IN_COLAB, local_repo_path=local_repo_dirPath)\n",
    "\n",
    "## Anthropomorphic phantoms ##\n",
    "##############################\n",
    "fig_size_XCAT=2.5\n",
    "indexes_XCAT = [300, 305, 310, 315, 320, 325]\n",
    "\n",
    "test_array_names = ['test-actMap.npy', 'test-highCountImage.npy', 'test-obliqueImage.npy']\n",
    "#test_array_names = ['test-actMap.npy']\n",
    "test_sino = 'test-highCountSino-382x513.npy'\n",
    "\n",
    "train_array_names = ['train-actMap.npy', 'train-highCountImage.npy', 'train-obliqueImage.npy']\n",
    "train_sino = 'train-highCountSino-382x513.npy'\n",
    "\n",
    "\n",
    "## QA phantoms ##\n",
    "#################\n",
    "fig_size_QA=2.5\n",
    "indexes_QA = [12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "\n",
    "NEMA_array_names = ['QA-NEMA-actMap.npy', 'QA-NEMA-highCountImage.npy', 'QA-NEMA-obliqueImage.npy']\n",
    "NEMA_sino = 'QA-NEMA-highCountSino.npy'\n",
    "\n",
    "Pinwheel_array_names = ['QA-Pinwheel-actMap.npy', 'QA-Pinwheel-highCountImage.npy', 'QA-Pinwheel-obliqueImage.npy']\n",
    "Pinwheel_sino = 'QA-Pinwheel-highCountSino.npy'\n",
    "\n",
    "\n",
    "#actMap = 'QA-Radial-actMap.npy'\n",
    "#sino = 'QA-Radial-highCountSino.npy'\n",
    "\n",
    "#actMap = 'QA-Axial-actMap.npy'\n",
    "#sino = 'QA-Axial-highCountSino.npy'\n",
    "\n",
    "## Network Configs ##\n",
    "#####################\n",
    "\n",
    "checkpoint_fileName_90x90 = 'checkpoint-new_data-old_net-90x90-100epochs'\n",
    "config_90x90 = {\n",
    "  \"SI_dropout\": False,  \"SI_exp_kernel\": 4,  \"SI_gen_fill\": 0,  \"SI_gen_final_activ\": nn.Tanh(),  \"SI_gen_hidden_dim\": 23,\n",
    "  \"SI_gen_mult\": 1.6605902406330195,  \"SI_gen_neck\": 5,  \"SI_gen_z_dim\": 789,  \"SI_layer_norm\": \"instance\",  \"SI_normalize\": True,  \"SI_pad_mode\": \"zeros\",  \"SI_scale_fixed\": 8100,  \"batch_size\": 71,  \"gen_b1\": 0.2082092731474774,  \"gen_b2\": 0.27147903136187507,\n",
    "  \"gen_lr\": 0.0005481469822215635, \"sup_criterion\": nn.MSELoss(),\n",
    "  \"sino_size\":90, \"sino_channels\": 3, \"image_channels\":1, \"image_size\":90, \"train_SI\": True, \"network_type\": \"SUP\"\n",
    "}\n",
    "\n",
    "checkpoint_fileName_180x180 = 'checkpoint-new_data-old_net-180x180-100epochs'\n",
    "config_180x180 = {\n",
    "  \"SI_dropout\": False,  \"SI_exp_kernel\": 4,  \"SI_gen_fill\": 0,  \"SI_gen_final_activ\": nn.Tanh(),  \"SI_gen_hidden_dim\": 23,\n",
    "  \"SI_gen_mult\": 1.6605902406330195,  \"SI_gen_neck\": 5,  \"SI_gen_z_dim\": 789,  \"SI_layer_norm\": \"instance\",  \"SI_normalize\": True,  \"SI_pad_mode\": \"zeros\",  \"SI_scale_fixed\": 8100,  \"batch_size\": 71,  \"gen_b1\": 0.2082092731474774,  \"gen_b2\": 0.27147903136187507,\n",
    "  \"gen_lr\": 0.0005481469822215635, \"sup_criterion\": nn.MSELoss(),\n",
    "  \"sino_size\":180, \"sino_channels\": 3, \"image_channels\":1, \"image_size\":90, \"train_SI\": True, \"network_type\": \"SUP\"\n",
    "}\n",
    "\n",
    "\n",
    "### Plots Images ###\n",
    "####################\n",
    "image_tensor, sino_tensor = PlotPhantomRecons(test_array_names, test_sino, config_90x90, paths, indexes_XCAT, checkpoint_fileName_90x90, fig_size_XCAT, device)\n",
    "image_tensor, sino_tensor = PlotPhantomRecons(test_array_names, test_sino, config_180x180, paths, indexes_XCAT, checkpoint_fileName_180x180, fig_size_XCAT, device)\n",
    "\n",
    "#image_tensor, sino_tensor = PlotPhantomRecons(NEMA_array_names, NEMA_sino, config_90x90, paths, indexes, checkpoint_fileName_90x90, fig_size_QA, device)\n",
    "#image_tensor, sino_tensor = PlotPhantomRecons(Pinwheel_array_names, Pinwheel_sino, config_90x90, paths, indexes, checkpoint_fileName_90x90, fig_size_QA, device)\n",
    "\n",
    "\n",
    "#############\n",
    "## Metrics ##\n",
    "#############\n",
    "\n",
    "#frame_SSIM_MLEM, placeholder = calculate_metric(MLEM_output, image_tensor, SSIM, dataframe = True, label='MLEM, SSIM')\n",
    "#frame_MSE_MLEM, placeholder =  calculate_metric(MLEM_output, image_tensor, MSE, dataframe = True, label='MLEM, MSE')\n",
    "#print('################### MLEM ###################')\n",
    "#print(frame_SSIM_MLEM.T)\n",
    "#print(frame_MSE_MLEM.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DiM_F1KL1cLd"
   },
   "outputs": [],
   "source": [
    "#################\n",
    "## Set Options ##\n",
    "#################\n",
    "\n",
    "tune_exp_name='search-Quartile-lowSSIM-tunedSSIM-D'\n",
    "save_fig=False\n",
    "\n",
    "titlesize=13\n",
    "fontsize=12\n",
    "ticksize=10\n",
    "dpi=800\n",
    "figsize=(10,8)\n",
    "\n",
    "fig = plt.figure(figsize=figsize, dpi=dpi)\n",
    "gs = gridspec.GridSpec(ncols=100, nrows=100)\n",
    "\n",
    "# Top Row Axes #\n",
    "ax1 = fig.add_subplot(gs[0:25,   0:100])\n",
    "ax2 = fig.add_subplot(gs[38:62,   0:100])\n",
    "ax3 = fig.add_subplot(gs[75:100,  0:100])\n",
    "\n",
    "\n",
    "## Plots ###\n",
    "\n",
    "refresh_repo(IN_COLAB, local_repo_path=local_repo_dirPath)\n",
    "\n",
    "result_grid, bestResult_logDir = PlotFrame(paths, tune_exp_name, ax1, 'batch_step', 'Batch Step', 'MSE', 'MSE', ylim=(4,20), logy=True)\n",
    "ax1.set_title('(A) MSE Learning Curves', fontsize=titlesize)\n",
    "\n",
    "result_grid, bestResult_logDir = PlotFrame(paths, tune_exp_name, ax2, 'batch_step', 'Batch Step', 'SSIM', 'SSIM', ylim=(0,0.8), logy=False)\n",
    "ax2.set_title('(B) SSIM Learning Curves', fontsize=titlesize)\n",
    "\n",
    "result_grid, bestResult_logDir = PlotFrame(paths, tune_exp_name, ax3, 'batch_step', 'Batch Step', 'CUSTOM', 'Local Distributions Metric', ylim=(300,500))\n",
    "ax3.set_title('(A) LDM Learning Curves', fontsize=titlesize)\n",
    "\n",
    "# Best Result #\n",
    "\n",
    "print(bestResult_logdir)\n",
    "\n",
    "# Save Fig? #\n",
    "\n",
    "if save_fig:\n",
    "    plot_save_name='figure-tuning'\n",
    "    savefig(os.path.join(paths['plot_dirPath'], plot_save_name+'.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_sPXBVEODKlR"
   },
   "outputs": [],
   "source": [
    "print(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFWg1RoN4NVJ"
   },
   "source": [
    "## Load: Test Dataframes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAmVEnJChNGK"
   },
   "source": [
    "### Plot Test Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-tDENcFyMMC"
   },
   "source": [
    "# Sort: Dataset by Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwU5ioxR6bHg"
   },
   "source": [
    "### Save Datasets & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PTrqg3MHNl1x"
   },
   "outputs": [],
   "source": [
    "#save_sino_path = '/content/drive/MyDrive/Repository/PET_Data/quartile_data/train_sino-lowSSIM-17500.npy'\n",
    "#save_image_path = '/content/drive/MyDrive/Repository/PET_Data/quartile_data/train_sino-lowSSIM-17500.npy'\n",
    "\n",
    "# Print sorted array shape & display a few images #\n",
    "print('save_sino_array.shape: ', save_sino_array.shape)\n",
    "print('save_image_array.shape: ', save_image_array.shape)\n",
    "\n",
    "print('save_sino_array sample images')\n",
    "print('save_image_array sample images')\n",
    "show_multiple_matched_tensors(torch.from_numpy(save_sino_array[500:509]))\n",
    "show_multiple_matched_tensors(torch.from_numpy(save_image_array[500:509]))\n",
    "\n",
    "\n",
    "# Save the sorted array to disk #\n",
    "save_sino_array.flush()\n",
    "save_image_array.flush()\n",
    "#np.save(save_sino_path, save_sino_array)\n",
    "#np.save(save_image_path, save_image_array)\n",
    "\n",
    "# Load the saved array and make sure it's the same size/has the same images #\n",
    "load_sino_array = np.load(save_sino_path, mmap_mode='r')\n",
    "load_image_array = np.load(save_image_path, mmap_mode='r')\n",
    "print('load_sino_array.shape: ', load_sino_array.shape)\n",
    "print('load_image_array.shape: ', load_image_array.shape)\n",
    "\n",
    "print('load_sino_array sample images')\n",
    "print('load_image_array sample images')\n",
    "show_multiple_matched_tensors(torch.from_numpy(load_sino_array[500:509]))\n",
    "show_multiple_matched_tensors(torch.from_numpy(load_image_array[500:509]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23TOba33L4qf"
   },
   "outputs": [],
   "source": [
    "## Find what GPU I'm using ##\n",
    "import torch\n",
    "print(torch.cuda.is_available())  # Should be True\n",
    "\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0AHpRBHQKzo9"
   },
   "source": [
    "Tensor board works for all experiments except the last one.\n",
    "My plotting function no longer works for any of the experiments."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
