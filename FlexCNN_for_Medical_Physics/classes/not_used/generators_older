import torch
from torch import nn




class Generator_288(nn.Module):
    def __init__(self, config, gen_SI=True, gen_skip_handling: str = 'classic', gen_flow_mode: str = 'coflow', enc_inject_channels=None, dec_inject_channels=None):
        '''
        Encoder-decoder generator with optional skip connections, producing 288x288 output.
        Contracting path: 288->144->72->36->18->9, neck: 1x1, 5x5, or 9x9, expanding path: 9->18->36->72->144->288.
        Skip handling modes:
            - classic: standard U-Net add/concat/none skips (no injection).
            - 1x1Conv: skip + optional frozen features are concatenated then reduced via 1x1 conv at decoder stages.
        Injection channel tuples (enc/dec) are passed explicitly (order: 144, 36, 9); use None or zeros to disable.
        '''
        super(Generator_288, self).__init__()

        if gen_SI:
            input_size = config['gen_sino_size']
            input_channels = config['gen_sino_channels']
            output_size = config['gen_image_size']
            output_channels = config['gen_image_channels']

            normalize_key = 'SI_normalize'
            fixed_key = 'SI_fixedScale'
            init_key = 'SI_learnedScale_init'
            skip_key = 'SI_skip_mode'

            neck = config['SI_gen_neck']
            exp_kernel = config['SI_exp_kernel']
            z_dim = config['SI_gen_z_dim']
            hidden_dim = config['SI_gen_hidden_dim']
            fill = config['SI_gen_fill']
            mult = config['SI_gen_mult']
            norm = config['SI_layer_norm']
            pad = config['SI_pad_mode']
            drop = config['SI_dropout']

            self.final_activation = config['SI_gen_final_activ']
            self.normalize = config['SI_normalize']
        else:
            input_size = config['gen_image_size']
            input_channels = config['gen_image_channels']
            output_size = config['gen_sino_size']
            output_channels = config['gen_sino_channels']

            normalize_key = 'IS_normalize'
            fixed_key = 'IS_fixedScale'
            init_key = 'IS_learnedScale_init'
            skip_key = 'IS_skip_mode'

            neck = config['IS_gen_neck']
            exp_kernel = config['IS_exp_kernel']
            z_dim = config['IS_gen_z_dim']
            hidden_dim = config['IS_gen_hidden_dim']
            fill = config['IS_gen_fill']
            mult = config['IS_gen_mult']
            norm = config['IS_layer_norm']
            pad = config['IS_pad_mode']
            drop = config['IS_dropout']

            self.final_activation = config['IS_gen_final_activ']
            self.normalize = config['IS_normalize']

        self.skip_mode = config.get(skip_key, 'none')

        # Skip handling and injection configuration (architecture-level)
        self.skip_handling = gen_skip_handling
        if self.skip_handling not in ('classic', '1x1Conv'):
            raise ValueError('gen_skip_handling must be one of {classic, 1x1Conv}')

        self.flow_mode = gen_flow_mode
        if self.flow_mode not in ('coflow', 'counterflow'):
            raise ValueError('gen_flow_mode must be one of {coflow, counterflow}')

        def _normalize_tuple(cfg):
            if cfg is None:
                return (0, 0, 0)
            if len(cfg) != 3:
                raise ValueError('Injection tuples must have three entries (144,36,9 scales).')
            return tuple(int(x) for x in cfg)

        self.enc_inject_channels = _normalize_tuple(enc_inject_channels)
        self.dec_inject_channels = _normalize_tuple(dec_inject_channels)
        if self.skip_handling == 'classic' and (any(self.enc_inject_channels) or any(self.dec_inject_channels)):
            raise ValueError('Injection requires gen_skip_handling="1x1Conv"')
        self.enable_encoder_inject = self.skip_handling == '1x1Conv' and any(self.enc_inject_channels)
        self.enable_decoder_inject = self.skip_handling == '1x1Conv'

        self.output_scale_learnable = not bool(config.get(normalize_key, False))
        if self.output_scale_learnable:
            init_scale = float(config.get(init_key, config.get(fixed_key, 1.0)))
            self.log_output_scale = nn.Parameter(torch.log(torch.tensor(init_scale, dtype=torch.float32)))
        else:
            init_scale = float(config.get(fixed_key, 1.0))
            self.register_buffer('fixed_output_scale', torch.tensor(init_scale, dtype=torch.float32))

        self.output_channels = output_channels
        self.output_size = output_size

        in_chan = input_channels
        out_chan = output_channels

        # Root scaling exponent for channel growth
        self.scaling_exp = 0.7  # Change as needed (e.g., 0.7)
        # Unique channel dims for each stage
        dim_0 = int(hidden_dim * mult ** (0 ** self.scaling_exp))
        dim_1 = int(hidden_dim * mult ** (1 ** self.scaling_exp))
        dim_2 = int(hidden_dim * mult ** (2 ** self.scaling_exp))
        dim_3 = int(hidden_dim * mult ** (3 ** self.scaling_exp))
        dim_4 = int(hidden_dim * mult ** (4 ** self.scaling_exp))
        dim_5 = int(hidden_dim * mult ** (5 ** self.scaling_exp))
        dim_6 = int(hidden_dim * mult ** (6 ** self.scaling_exp))

        if input_size != 288:
            raise ValueError('This generator is configured for 288x288 inputs.')

        # Contracting Path: 288 -> 144 -> 72 -> 36 -> 18 -> 9
        self.contract_blocks = nn.ModuleList([
            contract_block(in_chan, dim_0, 3, stride=2, padding=1, padding_mode=pad, fill=fill, norm=norm, drop=drop),   # 288->144
            contract_block(dim_0, dim_1, 3, stride=2, padding=1, padding_mode=pad, fill=fill, norm=norm, drop=drop),     # 144->72
            contract_block(dim_1, dim_2, 3, stride=2, padding=1, padding_mode=pad, fill=fill, norm=norm, drop=drop),     # 72->36
            contract_block(dim_2, dim_3, 3, stride=2, padding=1, padding_mode=pad, fill=fill, norm=norm, drop=drop),     # 36->18
            contract_block(dim_3, dim_4, 3, stride=2, padding=1, padding_mode=pad, fill=fill, norm=norm, drop=drop),     # 18->9
        ])

        self.neck = self._build_neck(neck, dim_4, dim_5, dim_6, z_dim, pad, fill, norm, drop)
        self.expand_blocks = self._build_expand(exp_kernel, out_chan, dim_0, dim_1, dim_2, dim_3, dim_4, pad, fill, norm, drop, self.skip_handling)

        # Channel references for injection (144,36,9 scales)
        self.enc_stage_channels = (dim_0, dim_2, dim_4)
        # Decoder stages at resolutions 9 (pre first upsample), 36 (pre 36->144 upsample), 144 (pre final upsample)
        self.dec_stage_channels = (dim_0, dim_2, dim_4)
        self.dec_skip_channels = (dim_0, dim_2, dim_4)

        if self.skip_handling == '1x1Conv':
            self._build_injectors(pad, norm, drop)

    def _build_neck(self, neck, dim_4, dim_5, dim_6, z_dim, pad, fill, norm, drop):
        # neck='narrow': 1x1 bottleneck
        if neck == 'narrow':
            return nn.Sequential(
                contract_block(dim_4, dim_5, 3, stride=2, padding=1, padding_mode=pad, fill=fill, norm=norm, drop=drop),      # 9->5: floor((9+2-3)/2)+1=5
                contract_block(dim_5, dim_6, 3, stride=2, padding=1, padding_mode=pad, fill=fill, norm=norm, drop=drop),      # 5->3: floor((5+2-3)/2)+1=3
                contract_block(dim_6, z_dim, 3, stride=1, padding=0, padding_mode=pad, fill=0, norm='batch', drop=False),     # 3->1
                expand_block(z_dim, dim_6, 3, stride=2, padding=0, output_padding=0, padding_mode='replicate', fill=fill, norm=norm, drop=drop),  # 1->3
                expand_block(dim_6, dim_5, 4, stride=2, padding=2, output_padding=1, padding_mode='replicate', fill=fill, norm=norm, drop=drop),  # 3->5
                expand_block(dim_5, dim_4, 3, stride=2, padding=1, output_padding=0, padding_mode='replicate', fill=fill, norm=norm, drop=drop),  # 5->9: (5-1)*2+3-2+0=9
            )
        # neck='medium': 5x5 bottleneck
        if neck == 'medium':
            return nn.Sequential(
                contract_block(dim_4, dim_5, 3, stride=2, padding=1, padding_mode=pad, fill=fill, norm=norm, drop=drop),      # 9->5: floor((9+2-3)/2)+1=5
                contract_block(dim_5, dim_5, 5, stride=1, padding=2, padding_mode=pad, fill=fill, norm=norm, drop=drop),      # 5->5
                contract_block(dim_5, dim_5, 5, stride=1, padding=2, padding_mode=pad, fill=fill, norm=norm, drop=drop),      # 5->5
                contract_block(dim_5, dim_5, 5, stride=1, padding=2, padding_mode=pad, fill=fill, norm=norm, drop=drop),      # 5->5
                contract_block(dim_5, dim_5, 5, stride=1, padding=2, padding_mode=pad, fill=fill, norm=norm, drop=drop),      # 5->5
                expand_block(dim_5, dim_4, 3, stride=2, padding=1, output_padding=0, padding_mode='replicate', fill=fill, norm=norm, drop=drop),  # 5->9: (5-1)*2+3-2+0=9
            )
        # neck='wide': 9x9 bottleneck
        if neck == 'wide':
            return nn.Sequential(
                contract_block(dim_4, dim_4, kernel_size=5, stride=1, padding=2, padding_mode=pad, fill=fill, norm=norm, drop=drop),  # 9->9
                contract_block(dim_4, dim_4, kernel_size=5, stride=1, padding=2, padding_mode=pad, fill=fill, norm=norm, drop=drop),  # 9->9
                contract_block(dim_4, dim_4, kernel_size=5, stride=1, padding=2, padding_mode=pad, fill=fill, norm=norm, drop=drop),  # 9->9
                contract_block(dim_4, dim_4, kernel_size=5, stride=1, padding=2, padding_mode=pad, fill=fill, norm=norm, drop=drop),  # 9->9
                contract_block(dim_4, dim_4, kernel_size=5, stride=1, padding=2, padding_mode=pad, fill=fill, norm=norm, drop=drop),  # 9->9
            )
        raise ValueError('neck must be one of {narrow, medium, wide} for Generator_288')

    def _build_expand(self, exp_kernel, out_chan, dim_0, dim_1, dim_2, dim_3, dim_4, pad, fill, norm, drop, skip_handling):
        # Expanding Path: 9 -> 18 -> 36 -> 72 -> 144 -> 288
        if exp_kernel == 3:
            stage_params = [
                (3, 2, 1, 1),  # 9->18
                (3, 2, 1, 1),  # 18->36
                (3, 2, 1, 1),  # 36->72
                (3, 2, 1, 1),  # 72->144
                (3, 2, 1, 1),  # 144->288
            ]
        elif exp_kernel == 4:
            stage_params = [
                (4, 2, 1, 0),  # 9->18
                (4, 2, 1, 0),  # 18->36
                (4, 2, 1, 0),  # 36->72
                (4, 2, 1, 0),  # 72->144
                (4, 2, 1, 0),  # 144->288
            ]
        else:
            raise ValueError('exp_kernel must be 3 or 4')

        def in_ch(base):
            if skip_handling == '1x1Conv':
                return base
            return base * 2 if self.skip_mode == 'concat' else base

        blocks = nn.ModuleList()
        blocks.append(expand_block(in_ch(dim_4), dim_3, stage_params[0][0], stage_params[0][1], stage_params[0][2], stage_params[0][3], padding_mode='replicate', fill=fill, norm=norm, drop=drop))
        blocks.append(expand_block(in_ch(dim_3), dim_2, stage_params[1][0], stage_params[1][1], stage_params[1][2], stage_params[1][3], padding_mode='replicate', fill=fill, norm=norm, drop=drop))
        blocks.append(expand_block(in_ch(dim_2), dim_1, stage_params[2][0], stage_params[2][1], stage_params[2][2], stage_params[2][3], padding_mode='replicate', fill=fill, norm=norm, drop=drop))
        blocks.append(expand_block(in_ch(dim_1), dim_0, stage_params[3][0], stage_params[3][1], stage_params[3][2], stage_params[3][3], padding_mode='replicate', fill=fill, norm=norm, drop=drop))
        blocks.append(expand_block(in_ch(dim_0), out_chan, stage_params[4][0], stage_params[4][1], stage_params[4][2], stage_params[4][3], padding_mode='replicate', fill=fill, norm=norm, drop=drop, final_layer=True))
        return blocks

    def _build_injectors(self, pad, norm, drop):
        def _make_proj(in_ch, out_ch):
            return nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=1, padding=0)

        # Encoder injectors (only if requested)
        enc_keys = ['enc_144', 'enc_36', 'enc_9']
        enc_chs = self.enc_stage_channels
        self.enc_injectors = nn.ModuleDict()
        for key, base_ch, inj_ch in zip(enc_keys, enc_chs, self.enc_inject_channels):
            if inj_ch > 0:
                self.enc_injectors[key] = _make_proj(base_ch + inj_ch, base_ch)

        # Decoder injectors (always in 1x1Conv mode)
        dec_keys = ['dec_144', 'dec_36', 'dec_9']
        dec_chs = self.dec_stage_channels
        skip_chs = self.dec_skip_channels
        self.dec_injectors = nn.ModuleDict()
        for key, base_ch, skip_ch, inj_ch in zip(dec_keys, dec_chs, skip_chs, self.dec_inject_channels):
            total_in = base_ch
            if self.skip_mode != 'none':
                total_in += skip_ch
            total_in += inj_ch
            self.dec_injectors[key] = _make_proj(total_in, base_ch)

    def _merge(self, skip, x):
        if self.skip_mode == 'none' or skip is None:
            return x
        if self.skip_mode == 'add':
            return x + skip
        if self.skip_mode == 'concat':
            return torch.cat([x, skip], dim=1)
        raise ValueError('skip_mode must be one of {none, add, concat}')

    def forward(self, input, frozen_encoder_features=None, frozen_decoder_features=None, return_features: bool = False):
        batch_size = len(input)

        # ============================================================================
        # SETUP AND VALIDATION
        # ============================================================================
        if self.skip_handling == 'classic' and (frozen_encoder_features is not None or frozen_decoder_features is not None):
            raise ValueError('Frozen features provided but gen_skip_handling is classic.')

        # Route frozen features based on flow mode (coflow: unchanged, counterflow: swap)
        enc_feats_in = frozen_encoder_features
        dec_feats_in = frozen_decoder_features
        if self.flow_mode == 'counterflow':
            enc_feats_in, dec_feats_in = dec_feats_in, enc_feats_in

        enc_feats_in = tuple(enc_feats_in) if enc_feats_in is not None else None
        dec_feats_in = tuple(dec_feats_in) if dec_feats_in is not None else None

        if self.skip_handling == '1x1Conv':
            if any(self.enc_inject_channels) and enc_feats_in is None:
                raise ValueError('Encoder injection requested but frozen_encoder_features not provided.')
            if self.enable_decoder_inject and dec_feats_in is None and any(self.dec_inject_channels):
                raise ValueError('Decoder injection requested but frozen_decoder_features not provided.')

        def _assert_match(tensor, target_h, target_w, expected_c, label):
            if tensor is None:
                raise ValueError(f'Missing tensor for {label}')
            h, w = tensor.shape[-2:]
            if h != target_h or w != target_w:
                raise ValueError(f'Shape mismatch for {label}: expected {target_h}x{target_w}, got {h}x{w}')
            if tensor.shape[1] != expected_c:
                raise ValueError(f'Channel mismatch for {label}: expected {expected_c}, got {tensor.shape[1]}')

        # ============================================================================
        # ENCODER: Contraction 288 -> 144 -> 72 -> 36 -> 18 -> 9 with injection
        # ============================================================================
        skips = []
        a = input
        for idx, block in enumerate(self.contract_blocks):
            a = block(a)
            # Inject frozen features at scales 144 (idx=0), 36 (idx=2), 9 (idx=4)
            if self.skip_handling == '1x1Conv' and idx in (0, 2, 4):
                inj_idx = {0: 0, 2: 1, 4: 2}[idx]
                inj_ch = self.enc_inject_channels[inj_idx]
                inj_feat = enc_feats_in[inj_idx]
                _assert_match(inj_feat, a.shape[-2], a.shape[-1], inj_ch, f'encoder_inject_{inj_idx}')
                key = ('enc_144', 'enc_36', 'enc_9')[inj_idx]
                a = torch.cat([a, inj_feat], dim=1) # Concatenate along channel dimension
                a = self.enc_injectors[key](a)      # Project back to base channels
            skips.append(a)

        if return_features:
            encoder_feats = [skips[0], skips[2], skips[4]]  # 144, 36, 9

        # ============================================================================
        # BOTTLENECK
        # ============================================================================
        a = self.neck(a)

        # ============================================================================
        # DECODER: Expansion with injection at three stages
        # ============================================================================

        # --- DECODER STAGE 1: 9x9 -> 18x18 ---
        if self.skip_handling == '1x1Conv':
            inj_feat = dec_feats_in[2] if dec_feats_in is not None else None
            inj_ch = self.dec_inject_channels[2]
            _assert_match(inj_feat, skips[4].shape[-2], skips[4].shape[-1], inj_ch, 'decoder_inject_9')
            parts = [a] # Current decoder features
            if self.skip_mode != 'none':
                parts.append(skips[4])         # If you are using skips, add the skip connection channels
            parts.append(inj_feat)             # Add the injection features
            a = torch.cat(parts, dim=1)        # Concatenate along channel dimension
            a = self.dec_injectors['dec_9'](a) # Project back to base channels
            if return_features:
                decoder_feat_9 = a             # Store features before upsample
        else:
            a = self._merge(skips[4], a)
            if return_features:
                decoder_feat_9 = a

        a = self.expand_blocks[0](a)  # 9 -> 18

        # --- INTERMEDIATE STAGES: 18/36 (classic mode only) ---
        if self.skip_handling == 'classic':
            a = self._merge(skips[3], a)
        a = self.expand_blocks[1](a)  # 18 -> 36

        if self.skip_handling == 'classic':
            a = self._merge(skips[2], a)
        a = self.expand_blocks[2](a)  # 36 -> 72

        # --- DECODER STAGE 2: 36x36 -> 144x144 ---
        if self.skip_handling == '1x1Conv':
            inj_feat = dec_feats_in[1] if dec_feats_in is not None else None
            inj_ch = self.dec_inject_channels[1]
            _assert_match(inj_feat, skips[2].shape[-2], skips[2].shape[-1], inj_ch, 'decoder_inject_36')
            parts = [a]
            if self.skip_mode != 'none':
                parts.append(skips[2])
            parts.append(inj_feat)
            a = torch.cat(parts, dim=1)
            a = self.dec_injectors['dec_36'](a)
            if return_features:
                decoder_feat_36 = a
        else:
            if return_features:
                decoder_feat_36 = a
            a = self._merge(skips[1], a)

        a = self.expand_blocks[3](a)  # 72 -> 144

        # --- DECODER STAGE 3: 144x144 (before final upsample) ---
        if self.skip_handling == '1x1Conv':
            inj_feat = dec_feats_in[0] if dec_feats_in is not None else None
            inj_ch = self.dec_inject_channels[0]
            _assert_match(inj_feat, skips[0].shape[-2], skips[0].shape[-1], inj_ch, 'decoder_inject_144')
            parts = [a]
            if self.skip_mode != 'none':
                parts.append(skips[0])
            parts.append(inj_feat)
            a = torch.cat(parts, dim=1)
            a = self.dec_injectors['dec_144'](a)
            if return_features:
                decoder_feat_144 = a
        else:
            if return_features:
                decoder_feat_144 = a
            a = self._merge(skips[0], a)

        a = self.expand_blocks[4](a)  # 144 -> 288

        # ============================================================================
        # POST-PROCESSING: Cropping, activation, normalization, scaling
        # ============================================================================
        if a.shape[-1] > self.output_size:
            crop_size = self.output_size
            margin = (a.shape[-1] - crop_size) // 2
            a = a[:, :, margin:margin+crop_size, margin:margin+crop_size]

        if self.final_activation:
            a = self.final_activation(a)

        if self.normalize:
            a = torch.reshape(a, (batch_size, self.output_channels, self.output_size**2))
            a = nn.functional.normalize(a, p=1, dim=2)
            a = torch.reshape(a, (batch_size, self.output_channels, self.output_size, self.output_size))

        scale = torch.exp(self.log_output_scale) if self.output_scale_learnable else self.fixed_output_scale
        a = a * scale

        # ============================================================================
        # RETURN
        # ============================================================================
        if return_features:
            return {
                'output': a,
                'encoder': [encoder_feats[0], encoder_feats[1], encoder_feats[2]],
                'decoder': [decoder_feat_144, decoder_feat_36, decoder_feat_9],
            }
        return a




###########################
##### Generator Class #####
###########################

class Generator(nn.Module):
    def __init__(self, config, gen_SI=True):
        '''
        A class to generate a 90x90-->90x90 or 180x180-->90x90 encoder-decoder network.
        The role of each item in the "config" dictionary is commented below.

        Args:
            config: Dictionary containing network hyperparameters and data dimensions (image_size, sino_size, 
                    image_channels, sino_channels). The constructor uses these to automatically determine 
                    input_size, input_channels, and output_channels based on gen_SI.
            gen_SI: Boolean - True if generating images from sinograms (SI), False if generating sinograms 
                    from images (IS). In a cycle-consistent network, this class generates two networks from 
                    the same config dictionary.
        '''
        
        super(Generator, self).__init__()
        
        # Determine input/output sizes and channels, and scale keys, based on direction
        if gen_SI:  # Sinogram → Image
            input_size = config['sino_size']
            input_channels = config['sino_channels']
            output_size = config['image_size']
            output_channels = config['image_channels']

            normalize_key = 'SI_normalize'    
            fixed_key = 'SI_fixedScale'
            init_key = 'SI_learnedScale_init'
        else:        # Image → Sinogram
            input_size = config['image_size']
            input_channels = config['image_channels']
            output_size = config['sino_size']
            output_channels = config['sino_channels']

            normalize_key = 'IS_normalize'    
            fixed_key = 'IS_fixedScale'
            init_key = 'IS_learnedScale_init'

        # Determine whether output scale is learnable. If normalizing, scale is fixed (not learnable).
        self.output_scale_learnable = not(bool(config.get(normalize_key, False)))

        # Determine initial scale based on whether it's learnable
        if self.output_scale_learnable:
            # Learnable: prefer init_key, fallback to fixed_key or 1.0
            init_scale = float(config.get(init_key, config.get(fixed_key, 1.0)))
            self.log_output_scale = nn.Parameter(torch.log(torch.tensor(init_scale, dtype=torch.float32)))
        else:
            # Fixed: use fixed_key directly (or fallback to 1.0)
            init_scale = float(config.get(fixed_key, 1.0))
            self.register_buffer('fixed_output_scale', torch.tensor(init_scale, dtype=torch.float32))

        self.output_channels = output_channels
        self.output_size = output_size
        
        ## If gen_SI == True, we use the "SI.." keys from the config dictionary to construct the generator network. ##
        if gen_SI:
            # The following instance variables are defined since these will be used in the forward() method below. #
            self.final_activation = config['SI_gen_final_activ']    # {nn.Tanh(), nn.Sigmoid(), None}
                                                                    # Type of activation function employed at the very end of network
            self.normalize=config['SI_normalize']                   # {True, False} : Normalization

            ## The following variables are used in the network constructor, and not the forward() method, so there is no need for instance variables.

            neck=config['SI_gen_neck'] #            {1,5,11} :          Width of narrowest part (neck) of the network. The smaller the number, the narrower the neck.
            exp_kernel=config['SI_exp_kernel'] #    {3,4} :             Square kernel width (or height) for the expanding part of the network.
            z_dim=config['SI_gen_z_dim'] #          (Any real number) : Number of channels in the network neck, if neck=1. If neck=5 or 11, this parameter isn't used.
            hidden_dim=config['SI_gen_hidden_dim']# (Any real number) : scales all channels in network by the same linear factor. Larger hidden_dim -->more complex network
            fill=config['SI_gen_fill'] #            {0,1,2,3} :         Number of "constant size" 2D convolutions in each block
            mult=config['SI_gen_mult'] #            (Any real number) : Multiplicative factor by which network channels increase as the layers decrease in height & width
            norm=config['SI_layer_norm'] #          {'instance', 'batch', 'none'} : Type of layer normalization
            pad=config['SI_pad_mode'] #             {'zeros', 'reflect'} :          Type of padding in each layer/block
            drop=config['SI_dropout'] #             {'True', 'False'} :             Whether dropout is used in the network

        #If gen_SI == False, we use the "IS.." keys from the config dictionary to construct the generator network. ##
        else:
            self.final_activation = config['IS_gen_final_activ']
            self.normalize=config['IS_normalize']

            neck=config['IS_gen_neck']
            exp_kernel=config['IS_exp_kernel']
            z_dim=config['IS_gen_z_dim']
            hidden_dim=config['IS_gen_hidden_dim']
            fill=config['IS_gen_fill']
            mult=config['IS_gen_mult']
            norm=config['IS_layer_norm']
            pad=config['IS_pad_mode']
            drop=config['IS_dropout']

        ## Abbreviations used for Block Definitions -- used to make code less awkward ##
        in_chan = input_channels
        out_chan = output_channels

        dim_0 = int(hidden_dim*mult**0) # Number of output channels of 1st block/input channels of 2nd block
        dim_1 = int(hidden_dim*mult**1) # Number of output channels of 2nd block/input channels of 3rd block
        dim_2 = int(hidden_dim*mult**2) # Follows pattern above
        dim_3 = int(hidden_dim*mult**3)
        dim_4 = int(hidden_dim*mult**4)
        dim_5 = int(hidden_dim*mult**5)

        ### Block Definitions ###

        ## Build the Contracting Path ##
        # The formula for the output size of a transposed convolution (nn.Conv2d) in Pytorch is as follows:
        # Hf = [Hi+2*padding-dilation(kernel-1)-1]/stride + 1 = [Hi+2*padding-kernel]/stride + 1 (for dialation=1)

        if input_size==180:
            self.contract = nn.Sequential(
                # nn.Conv2d: Hf = [Hi+2*padding-dilation(kernel-1)-1]/stride + 1 = [Hi+2*padding-kernel]/stride + 1 (for dialation=1)
                # Sinogram Shape: (3,90,90)
                contract_block(in_chan, dim_0, 3, stride=2, padding=1, padding_mode=pad, fill=fill, norm=norm, drop=drop), # H = [180+2-3]/2 + 1 = 90
                contract_block(dim_0,   dim_1, 3, stride=2, padding=1, padding_mode=pad, fill=fill, norm=norm, drop=drop), # H = [90+2-3]/2 + 1 = 45.5
                contract_block(dim_1,   dim_2, 3, stride=2, padding=1, padding_mode=pad, fill=fill, norm=norm, drop=drop), # H = [45+2-3]/2 + 1 = 23
                contract_block(dim_2,   dim_2, 4, stride=2, padding=1, padding_mode=pad, fill=fill, norm=norm, drop=drop), # H = [23+2-4]/2 + 1 = 11.5
            )
        elif input_size==90:
            self.contract = nn.Sequential(
                contract_block(in_chan, dim_0, 3, stride=2, padding=1, padding_mode=pad, fill=fill, norm=norm, drop=drop), # H = [90+2-3]/2 + 1 = 45.5  : a 90x90 input gives a 45x45 output
                contract_block(dim_0,   dim_1, 3, stride=2, padding=1, padding_mode=pad, fill=fill, norm=norm, drop=drop), # H = [45+2-3]/2 + 1 = 23    : a 45x45 input gives a 23x23 output
                contract_block(dim_1,   dim_2, 4, stride=2, padding=1, padding_mode=pad, fill=fill, norm=norm, drop=drop), # H = [23+2-4]/2 + 1 = 11.5  : a 23x23 input gives a 11x11 output
            )

        ## Build the Neck. There are 3 options ##
        # neck=1 gives the narrowest (1x1) neck #
        if neck==1:
            self.neck = nn.Sequential(
                contract_block(dim_2, dim_3, 4, stride=2, padding=1, padding_mode=pad, fill=fill, norm=norm, drop=drop), # H = [11+2-4]/2 + 1 = 5.5
                contract_block(dim_3, dim_4, 3, stride=2, padding=1, padding_mode=pad, fill=fill, norm=norm           ), # H = [5+2*1-3]/2 + 1 = 3
                contract_block(dim_4, z_dim, 3, stride=1, padding=0,                   fill=0,    norm='batch'        ), # H = 1   ||norm is set to 'batch' because 'instance' won't work on 1x1 layer
                expand_block(  z_dim, dim_4, 3, stride=2, padding=0,                   fill=fill, norm=norm           ), # H = [1-1]*2+5 = 3
                expand_block(  dim_4, dim_3, 4, stride=2, padding=2, output_padding=1, fill=fill, norm=norm           ), # H = [3-1]*2+4-2*2+1 = 5
            )

        # neck=5 gives the middle width (5x5) neck #
        if neck==5:
            self.neck = nn.Sequential(
                contract_block(dim_2, dim_3, 4, stride=2, padding=1, padding_mode=pad, fill=fill, norm=norm, drop=drop), # H = [11+2-4]/2 + 1 = 5.5
                contract_block(dim_3, dim_3, 5, stride=1, padding=2, padding_mode=pad,            norm=norm           ), # H = [5+2*2-5]/1 + 1 = 5 (Constant Block)
                contract_block(dim_3, dim_3, 5, stride=1, padding=2, padding_mode=pad,            norm=norm           ), # H = [5+2*2-5]/1 + 1 = 5 (Constant Block)
                contract_block(dim_3, dim_3, 5, stride=1, padding=2, padding_mode=pad,            norm=norm           ), # H = [5+2*2-5]/1 + 1 = 5 (Constant Block)
                #contract_block(dim_3, dim_3, kernel_size=5, stride=1, padding=2, padding_mode=pad, norm=norm), # H = [5+2*2-5]/1 + 1 = 5 (Constant Block) # Add this next tuning!
            )

        # neck=11 gives the thickest (11x11) neck #
        if neck==11:
            self.neck = nn.Sequential(
                contract_block(dim_2, dim_2, kernel_size=5, stride=1, padding=2, padding_mode=pad, norm=norm), # H = [11+2*2-5]/1 + 1 = 11 (Constant Block)
                contract_block(dim_2, dim_2, kernel_size=5, stride=1, padding=2, padding_mode=pad, norm=norm), # H = [11+2*2-5]/1 + 1 = 11 (Constant Block)
                contract_block(dim_2, dim_2, kernel_size=5, stride=1, padding=2, padding_mode=pad, norm=norm), # H = [11+2*2-5]/1 + 1 = 11 (Constant Block)
                contract_block(dim_2, dim_2, kernel_size=5, stride=1, padding=2, padding_mode=pad, norm=norm), # H = [11+2*2-5]/1 + 1 = 11 (Constant Block)
                contract_block(dim_2, dim_2, kernel_size=5, stride=1, padding=2, padding_mode=pad, norm=norm), # H = [11+2*2-5]/1 + 1 = 11 (Constant Block)
            )

        ## Build the Expanding Blocks ##
        # The formula for the output size of a transposed convolution (nn.ConvTranspose2d:) in Pytorch is as follows:
        # Hf = (Hi-1)*stride -2*padding +dilation*(kernel-1) +output_padding+1
        #    = (Hi-1)*stride +kernel -2*padding +output_padding (for dialation=1)

        # For neck=1 or 5, the output from previous layers is 5x5. Therefore, these can use the same expanding blocks #
        if (neck==1 or neck==5):
            if exp_kernel==3:
            # Expanding block for neck=1 or 5, expanding kernel size = 3)
                self.expand = nn.Sequential(
                    expand_block(dim_3, dim_2,                      kernel_size=3, stride=2, padding=0, output_padding=0, fill=fill, norm=norm), # H = (5-1)*2  +3         = 11
                    expand_block(dim_2, dim_1,                      kernel_size=3, stride=2, padding=1, output_padding=1, fill=fill, norm=norm), # H = (11-1)*2 +3 -2*1 +1 = 22
                    expand_block(dim_1, dim_0,                      kernel_size=3, stride=2, padding=0, output_padding=0, fill=fill, norm=norm), # H = (22-1)*2 +3         = 45
                    expand_block(dim_0, out_chan, final_layer=True, kernel_size=3, stride=2, padding=1, output_padding=1, fill=fill, norm=norm), # H = (45-1)*2 +3 -2*1 +1 = 90
                )

            elif exp_kernel==4:
            # Expanding block for neck=1 or 5, expanding kernel size = 4
                self.expand = nn.Sequential(
                    expand_block(dim_3, dim_2,                      kernel_size=4, stride=2, padding=1, output_padding=1, fill=fill, norm=norm),  # H = (5-1)*2  +4 -2*1 +1 = 11
                    expand_block(dim_2, dim_1,                      kernel_size=4, stride=2, padding=1, output_padding=0, fill=fill, norm=norm),  # H = (11-1)*2 +4 -2*1    = 22
                    expand_block(dim_1, dim_0,                      kernel_size=4, stride=2, padding=1, output_padding=1, fill=fill, norm=norm),  # H = (21-1)*2 +4 -2*1 +1 = 45
                    expand_block(dim_0, out_chan, final_layer=True, kernel_size=4, stride=2, padding=1, output_padding=0, fill=fill, norm=norm),  # H = (45-1)*2 +4 -2*1    = 90
                )

        # For neck=11, the output is 11x11. This neck requires its own expanding blocks #
        if neck==11:
            if exp_kernel==3:
            # Expanding block for neck=11, expanding kernel size = 3
                self.expand = nn.Sequential(
                    expand_block(dim_2, dim_1,                      kernel_size=3, stride=2, padding=1, output_padding=1, fill=fill, norm=norm),  # H = (11-1)*2 +3 -2*1 +1 = 22
                    expand_block(dim_1, dim_0,                      kernel_size=3, stride=2, padding=0, output_padding=0, fill=fill, norm=norm),  # H = (22-1)*2 +3         = 45
                    expand_block(dim_0, out_chan, final_layer=True, kernel_size=3, stride=2, padding=1, output_padding=1, fill=fill, norm=norm),  # H = (45-1)*2 +3 -2*1 +1 = 90
                )

            if exp_kernel==4:
            # Expanding block for neck=11, expanding kernel size = 4
                self.expand = nn.Sequential(
                    expand_block(dim_2, dim_1,                      kernel_size=4, stride=2, padding=1, output_padding=0, fill=fill, norm=norm),  # H = (11-1)*2 +4 -2*1    = 22
                    expand_block(dim_1, dim_0,                      kernel_size=4, stride=2, padding=1, output_padding=1, fill=fill, norm=norm),  # H = (21-1)*2 +4 -2*1 +1 = 45
                    expand_block(dim_0, out_chan, final_layer=True, kernel_size=4, stride=2, padding=1, output_padding=0, fill=fill, norm=norm),  # H = (45-1)*2 +4 -2*1    = 90
                )

    def forward(self, input):
        # This method gets run when the network is called to produce an output from an input #

        batch_size = len(input)  # Get batch size

        a = self.contract(input) # Run input through contracting blocks
        a = self.neck(a)         # Run output from contracting blocks through the neck
        a = self.expand(a)       # Run outoput from the neck through the expanding blocks

        if self.final_activation:   # Optional final activations
            a = self.final_activation(a)
        if self.normalize:          # Optionally normalize
            a = torch.reshape(a,(batch_size, self.output_channels, self.output_size**2)) # Flattens each image
            a = nn.functional.normalize(a, p=1, dim = 2)
            a = torch.reshape(a,(batch_size, self.output_channels , self.output_size, self.output_size)) # Reshapes images back into square matrices

        if self.output_scale_learnable:
            scale = torch.exp(self.log_output_scale)
        else:
            scale = self.fixed_output_scale

        a = a * scale
        return a                    # Return the output
    



######################################
##### Block Generating Functions #####
######################################

def contract_block(in_channels, out_channels, kernel_size, stride, padding=0, padding_mode='reflect', fill=0, norm='batch', drop=False):
    '''
    Function to construct a single "contracting block." Each contracting block consists of one 2D convolutional layer, which decreases
    the size (height and width) of the data. There are then up to three 2D convolution layers which do not change the height or width
    (e.g. "constant size layers").

    in_channels:    number of channels at the input of contracting block
    out_channels:   number of channels at the output of contracting block
    kernel_size:    size of the kernel for the 1st 2D convolutional layer in the contracting block
    stride:         stride of the convolution for the 1st 2D convolutional layer in the contracting block
    padding:        amount of padding for the the 1st 2D convolutional layer in the contracting block
    padding_mode:   padding mode (options: "zeros", "reflect")
    fill:           number of "constant size" 2D convolutional layers
    norm:           type of layer normalization ("batch", "instance", or "none")
    dropout:        include dropout layers in the contracting block? (True or False)
    '''

    if norm=='batch':         norm = nn.BatchNorm2d(out_channels)
    elif norm=='instance':    norm = nn.InstanceNorm2d(out_channels)
    elif norm=='group':
            num_groups = min(8, out_channels)
            norm = nn.GroupNorm(num_groups, out_channels)
    else:
        norm = nn.Sequential()

    dropout = nn.Dropout() if drop==True else nn.Sequential()

    # Note: for the contracting block, normalization & dropout follow convolutional layers. For expanding blocks, the order is reversed.
    block1 =  nn.Sequential(
        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, padding_mode=padding_mode), norm, dropout, nn.ReLU())
    if fill==0:
        block2 = nn.Sequential() # If fill=0, there are no "constant size" convolutional layers, and so block2 is empty.
    if fill==1:
        block2 = nn.Sequential(nn.Conv2d(out_channels, out_channels, 3, 1, 1, padding_mode=padding_mode), norm, dropout, nn.ReLU())
    elif fill==2:
        block2 = nn.Sequential(nn.Conv2d(out_channels, out_channels, 3, 1, 1, padding_mode=padding_mode), norm, dropout, nn.ReLU(),
                                nn.Conv2d(out_channels, out_channels, 3, 1, 1, padding_mode=padding_mode), norm, dropout, nn.ReLU())
    elif fill==3:
        block2 = nn.Sequential(nn.Conv2d(out_channels, out_channels, 3, 1, 1, padding_mode=padding_mode), norm, dropout, nn.ReLU(),
                                nn.Conv2d(out_channels, out_channels, 3, 1, 1, padding_mode=padding_mode), norm, dropout, nn.ReLU(),
                                nn.Conv2d(out_channels, out_channels, 3, 1, 1, padding_mode=padding_mode), norm, dropout, nn.ReLU())
    return nn.Sequential(block1, block2)

def expand_block(in_channels, out_channels, kernel_size=3, stride=2, padding=0, output_padding=0, padding_mode='zeros', fill=0, norm='batch', drop=False, final_layer=False):
    '''
    Function to construct a single "expanding block." Each expanding block consists of one 2D transposed convolution layer which increases
    the size of the incoming data (height and width). There are then up to three 2D convolution layers which do not change the height or
    width (e.g. "constant size layers").

    in_channels:    number of channels at the input of the expanding block
    out_channels:   number of channels at the output of the expanding block
    kernel_size:    size of the kernel for the 1st 2D transposed convolutional layer in the expanding block
    stride:         stride of the convolution for the 1st 2D transposed convolutional layer in the expanding block
    padding:        amount of padding for the the 1st 2D transposed convolutional layer in the expanding block
    padding_mode:   padding mode (ex: "zeros", "reflect")
    fill:           number of "constant size" 2D convolutional layers
    norm:           type of layer normalization ("batch", "instance", or "none")
    dropout:        include dropout in the expanding block (True or False)
    final_layer:    Is this the final layer in the expanding block? (True or False)
    '''

    if norm=='batch':         norm = nn.BatchNorm2d(out_channels)
    elif norm=='instance':    norm = nn.InstanceNorm2d(out_channels)
    elif norm=='group':
            num_groups = min(8, out_channels)
            norm = nn.GroupNorm(num_groups, out_channels)
    else:
        norm = nn.Sequential()
        
    dropout = nn.Dropout() if drop==True else nn.Sequential()

    # Note: for the expanding block, normalization & dropout precede convolutional layers in blocks 2-3. For expanding blocks, the order is reversed.
    block1 = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, output_padding, padding_mode=padding_mode)
    if fill==0:
        block2 = nn.Sequential()
    if fill==1:
        block2 = nn.Sequential(norm, dropout, nn.ReLU(), nn.Conv2d(out_channels, out_channels, 3, 1, 1, padding_mode=padding_mode))
    elif fill==2: # For
        block2 = nn.Sequential(norm, dropout, nn.ReLU(), nn.Conv2d(out_channels, out_channels, 3, 1, 1, padding_mode=padding_mode),
                                norm, dropout, nn.ReLU(), nn.Conv2d(out_channels, out_channels, 3, 1, 1, padding_mode=padding_mode))
    elif fill==3:
        block2 = nn.Sequential(norm, dropout, nn.ReLU(), nn.Conv2d(out_channels, out_channels, 3, 1, 1, padding_mode=padding_mode),
                                norm, dropout, nn.ReLU(), nn.Conv2d(out_channels, out_channels, 3, 1, 1, padding_mode=padding_mode),
                                norm, dropout, nn.ReLU(), nn.Conv2d(out_channels, out_channels, 3, 1, 1, padding_mode=padding_mode))

    if final_layer==False: # If not the final layer, I add normalization, dropout and activation.
        block3 = nn.Sequential(norm, dropout, nn.ReLU())
    else:                  # Otherwise, I leave off the normalization, dropout, and activation. This allows me to do it explicitly
                           # at the end of the network using tuned parameters.
        block3 = nn.Sequential()

    return nn.Sequential(block1, block2, block3)